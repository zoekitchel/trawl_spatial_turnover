---
title: "Apply Temporal and Spatial Standardization"
output: html_notebook
---

This code is Script 2 for Kitchel et al. TITLE manuscript.

- This project is a collaborative effort to describe changes in taxonomic composition  of fish communities around the world--as sampled by bottom trawl surveys.

- Code by ZoÃ« J. Kitchel

SESSION INFO TO DO


```{r setup}
library(tidyverse)
library(data.table)
library(here)
library(sp)
library(raster)
library(rgeos)
library(rgbif)
library(viridis)
library(gridExtra)
library(rasterVis)
library(concaveman)
library(sf)
library(viridis)
set.seed(1)
```

Load manually reduced fishglob database from prepare_fishglob_dataset.Rmd
```{r}
FishGlob.10year.spp_manualclean <- readRDS(here::here("data","cleaned","FishGlob.10year.spp_manualclean.rds"))
```


####Edit function to create grid which will allow us to maintain similar spatial footprint over time
From [here](https://strimas.com/post/hexagonal-grids/)

We will use cell size of 7,774.2 km^2, as that will match grid cell size of 8 in dggridr. We can't use the package dggridr unfortunately because it doesn't work for this version of R (and others have had this issue too). https://github.com/r-barnes/dggridR
For Norway we will use cell size of 23,322.2 km^2 because the sites are further away from each other.

Make sampling locations into spatial points
```{r sampling locations to sp}
#delete if NA for longitude or latitude
FishGlob.10year.spp_manualclean <- FishGlob.10year.spp_manualclean[complete.cases(FishGlob.10year.spp_manualclean[,.(longitude, latitude)])] 

```

Match lat/lon sampling points to hexagonal cells, so that we can see how many cells to keep to maintain a lot of observation points

```{r match lat lon to hex cells}
FishGlob.cells <- data.table()

#two potential cell sizes
  #set cell area (depends on whether or not it's Norway)
  cell_area_all  <- 7774.2 #km2 (8 from dggrdr)
  cell_area_norway <- 23322.2 #km2 (7 from dggrdr; if you want to use different resolution, not doing as of now)
  
all_survey_units <- unique(FishGlob.10year.spp_manualclean[,survey_unit])
  

for(i in 1:length(all_survey_units)){
  FishGlob.10year.spp_manualclean_subset <- FishGlob.10year.spp_manualclean[survey_unit == all_survey_units[i],]
  
  #unique lat lon combos
  FishGlob.10year.spp_manualclean_subset_unique <- unique(FishGlob.10year.spp_manualclean_subset[,.(longitude,latitude,haul_id,year)])
  
  #coordinates to Spatial Points Object
  if(max(FishGlob.10year.spp_manualclean_subset_unique[,longitude]) - min(FishGlob.10year.spp_manualclean_subset_unique[,longitude]) > 359){ #if survey region crosses dateline, use st_shift_longitude()
    sp <- FishGlob.10year.spp_manualclean_subset_unique %>%
          st_as_sf(coords = c("longitude","latitude"), crs = 4326) %>%
             st_shift_longitude()
  }else{
    sp <- FishGlob.10year.spp_manualclean_subset_unique %>%
          st_as_sf(coords = c("longitude","latitude"), crs = 4326)
  }
  
  sp.t <- as(sp, "Spatial")
  
  proj4string(sp.t) <- CRS("+proj=longlat")
  
proj <-  ifelse(max(FishGlob.10year.spp_manualclean_subset_unique[,longitude]) - min(FishGlob.10year.spp_manualclean_subset_unique[,longitude]) > 359, #if survey region crosses dateline, use +lon_0=-140 instead of +lon_0=0
         "+proj=robin +lon_0=-140 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=km +no_defs",
         "+proj=robin +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=km +no_defs")
  
  
  sp.p <- spTransform(sp.t, CRS(proj)) #note km^2 units
  
  #use Concaveman to convert points to polygon
  polygon  <- concaveman(sp, 2, 3)

  polygon_spapol <- as(polygon, "Spatial") #convert simple polygon feature to spatial polygon
  
  proj4string(polygon_spapol) <- CRS("+proj=longlat")
  
  polygon_spapol.p <- spTransform(polygon_spapol, CRS(proj)) #note km^2 units
  
  #create grid 
  #set cell_area based on whether or not it's the Norway survey
  cell_area_km <- ifelse(all_survey_units[i] %in% c("Nor-BTS-1","Nor-BTS-3"), cell_area_norway, cell_area_all) #note this is in kilometers (if you want to use different cell resolution for Norway)
  
  #calculate cell_diameter of hexagons from cell_areas
  cell_diameter_km <- sqrt(2 * cell_area_km / sqrt(3)) # in meters
  

  ext <- as(extent(polygon_spapol.p)
            + 2*cell_diameter_km #add a buffer to make sure all observations are assigned a cell
             , "SpatialPolygons")
 # plot(ext)
 # plot(sp.p, add = T, pch = ".")
  
  projection(ext) <- projection(polygon_spapol.p) #match projection
  
  # generate array of hexagon centers
  g <- spsample(ext, type = "hexagonal", cellsize = cell_diameter_km, offset = c(0.5, 0.5))
  
    # convert center points to hexagons
  g <- HexPoints2SpatialPolygons(g, dx = cell_diameter_km)
  
 plot(g)
 plot(sp.p, add = T, pch = ".")
 title(paste0(all_survey_units[i]))

  #link lat lon to cell#
    #where do they overlap
    sp.p$cell_ID <- over(sp.p,g) #over(x=location of queries, y = layer from which geometries are queried)
    
    #link lat long to cell #s
    FishGlob.10year.spp_manualclean_subset_unique[,cell_ID := sp.p$cell_ID][,cell_year_count := .N, .(cell_ID, year)]
    
    #link back to subsetted database of observations
    FishGlob.subset.cells <- FishGlob.10year.spp_manualclean_subset[FishGlob.10year.spp_manualclean_subset_unique, on = c("longitude", "latitude","year","haul_id")]
    
    FishGlob.cells <- rbind(FishGlob.cells, FishGlob.subset.cells)

    
#make sure all projections match for binding of polygons
polygon_spapol.forbind <- spTransform(polygon_spapol.p,
                                      CRS=CRS( "+proj=robin +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=km +no_defs"))

      polygon_spapol.forbind$survey_unit <- all_survey_units[i]
      
    #bind polygons into spdf
    if(i ==1){
      all_survey_units_polygon <- polygon_spapol.forbind #if first, just polygon to start
    }else{
      all_survey_units_polygon <- rbind(all_survey_units_polygon, polygon_spapol.forbind)  #if not first, bind new polygon to first polygon
    }
    
       
  
}
  
#writeOGR(all_survey_units_polygon, dsn = here::here("output/shapefiles"))
```




Merge all shapefiles together in order to send to Sea Around Us team to obtain fishing specific fishing data.
```{r}

```


________

Standardize observations by # of hauls per cell and # cells sampled per year

Remove any years that sample less than 70% of cells  ever sampled
Remove any cells that are sampled in less than 70% of years

```{r standardize observations all regions}

#account of data loss by standardization
data_loss <- data.table(survey_unit=all_survey_units,
                        year_threshold=as.numeric(NA),
                        cell_threshold=as.numeric(NA),
                        percent_years_excluded=as.numeric(NA),
                        percent_hauls_excluded_by_year=as.numeric(NA),
                        percent_obs_excluded_by_year=as.numeric(NA),
                        percent_cells_excluded=as.numeric(NA),
                        percent_hauls_excluded_total=as.numeric(NA),
                        percent_obs_excluded_total=as.numeric(NA))

FishGlob.wellsampledyearscells_complete <- data.table()

for (i in 1:length(all_survey_units)) {
      
      #subset to region
      FishGlob.cells.subset <- FishGlob.cells[survey_unit == all_survey_units[i],]
      
      #unique year, #cells  sampled
      year_cells_sampled <- unique(FishGlob.cells.subset[,.(year,cell_ID)])
      year_cells_sampled <- year_cells_sampled[,yearly_cell_count := .N,year]
      year_cells_sampled <- unique(year_cells_sampled[,.(year,yearly_cell_count)])
      
      #eliminate years with less than 70% of cells sampled
      year_benchmark <- 0.70
      benchmark_value <- year_benchmark*max(year_cells_sampled[,yearly_cell_count])
      
      #only keep years where over 70% of cells are sampled
      year_cells_sampled[,benchmark := yearly_cell_count >= benchmark_value]
      
      years_deleted <- unique(year_cells_sampled[benchmark == F,year]) #which years are left out?
      
      years_kept <-unique(year_cells_sampled[benchmark ==T,year]) #which years to keep
      
      years_deleted_percent <- round(length(years_deleted)/length(unique(year_cells_sampled[,year]))*100,1)
      

       #print the years that are left out
      print(ifelse(length(years_deleted) == 0, paste0(all_survey_units[i], " Years left out = 0"), paste0(" ",all_survey_units[i], " Years left out = ", years_deleted, collapse = ",")))
     
     print(paste0(years_deleted_percent, "% of Years Excluded"))
      
      #reduce to years that are well sampled
      FishGlob.cells.subset.wellsampledyears <- FishGlob.cells.subset[year %in% years_kept,]
      
      #how many observations does this remove?
      percent_obs_removed_year <- round((nrow(FishGlob.cells.subset)-nrow(FishGlob.cells.subset.wellsampledyears))/nrow(FishGlob.cells.subset)*100,2)
      
      percent_hauls_removed_year <- round((length(unique(FishGlob.cells.subset[,haul_id]))-length(unique(FishGlob.cells.subset.wellsampledyears[,haul_id])))/length(unique(FishGlob.cells.subset[,haul_id]))*100,2)
      
      #identify any cells that are not sampled in 70% of years
      FishGlob.cells.subset.wellsampledyears[,year_cell_count := length(unique(haul_id)),.(year,cell_ID)] # unique haul ids per cell per year
      
      cell_by_year <- unique(FishGlob.cells.subset.wellsampledyears[, .(cell_ID,year)])
      
      cell_by_year[,years_per_cell := .N,cell_ID]
      
      #cell ids to remove and keep
      #in any year, which cells are sampled in less than 70% of years
      #we'll make benchmark 70% just for now
      cell_benchmark <- 0.70
      benchmark_value_year_count <- cell_benchmark*max(cell_by_year[,years_per_cell])
      
      cell_id_remove <- unique(cell_by_year[years_per_cell<benchmark_value_year_count,cell_ID])
      
      cells_deleted_percent <- round(length(cell_id_remove)/length(unique(FishGlob.cells.subset.wellsampledyears[,cell_ID]))*100,1)
      
      #reduce to cells that are well sampled
      FishGlob.cells.subset.wellsampledyearscells <- FishGlob.cells.subset.wellsampledyears[!(cell_ID %in% cell_id_remove),]
      
      #What percent of hauls does this remove?
      hauls_removed_yearcell <- round((length(unique(FishGlob.cells.subset[,haul_id]))-length(unique(FishGlob.cells.subset.wellsampledyearscells[,haul_id])))/length(unique(FishGlob.cells.subset[,haul_id]))*100,1) 
      
      #What percent of observations does this remove?
      obs_removed_yearcell <- round((nrow(FishGlob.cells.subset)-nrow(FishGlob.cells.subset.wellsampledyearscells))/nrow(FishGlob.cells.subset)*100,1)
      
      cell_id_remove.string <- paste(cell_id_remove, collapse = ", ")
      obs_removed.string <- paste(obs_removed_yearcell, collapse = ", ")
      
      #build data table from this reduced output
      FishGlob.wellsampledyearscells_complete <- rbind(FishGlob.wellsampledyearscells_complete, FishGlob.cells.subset.wellsampledyearscells)
      
      #fill out table with statistics of dropped observations
      data_loss[i, "year_threshold"] = year_benchmark
      data_loss[i, "cell_threshold"] = cell_benchmark
      data_loss[i, "percent_years_excluded"] = years_deleted_percent
      data_loss[i, "percent_hauls_excluded_by_year"] = percent_hauls_removed_year
      data_loss[i, "percent_obs_excluded_by_year"] = percent_obs_removed_year
      data_loss[i, "percent_cells_excluded"] = cells_deleted_percent
      data_loss[i, "percent_hauls_excluded_total"] = hauls_removed_yearcell
      data_loss[i, "percent_obs_excluded_total"] = obs_removed_yearcell
      
        #print portion of cells that are left out
      print(ifelse(length(cell_id_remove) == 0, paste0(all_survey_units[i], " Cells left out = 0"), paste0(all_survey_units[i], " Cells left out = ", cell_id_remove.string, ", ",cells_deleted_percent, "% Cells Excluded, ",hauls_removed_yearcell,"% Hauls Removed, ", obs_removed_yearcell, "% Observations Removed")))
      
      }
     


#now, check again to see if any are less than 10 years
FishGlob.wellsampledyearscells_complete[,years_sampled_update := length(unique(year)),.(survey_unit)]
FishGlob.wellsampledyearscells_complete.10year <- FishGlob.wellsampledyearscells_complete[years_sampled_update >= 10,]

#only keep survey units for which fewer than 20% of observations were deleted by 70% thresholds
survey_units_keep <- unique(data_loss[percent_obs_excluded_total <= 20,survey_unit])

FishGlob.wellsampledyearscells_complete.final <- FishGlob.wellsampledyearscells_complete.10year[survey_unit %in% survey_units_keep,]

saveRDS(FishGlob.wellsampledyearscells_complete.final, here::here("data","cleaned","FishGlob.wellsampledyearscells_complete.final.rds"))


```