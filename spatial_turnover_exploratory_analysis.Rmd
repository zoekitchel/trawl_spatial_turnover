---
title: "Spatial Turnover Exploratory Analysis"
output: html_notebook
---

Instructions from Malin:

Is anyone up for an exploratory analysis with the trawl data? It would be very cool to look at changes in spatial turnover, similar to [Magurran, Dornelas, Moyes, Gotelli, McGill et al. 2015](http://www.nature.com/ncomms/2015/150924/ncomms9405/full/ncomms9405.html) but across a much wider set of regions. An idea from conversations at [HIFMB](https://hifmb.de/en/) yesterday. 

From Magurran et al. *"Here, we analyse an exceptionally comprehensive 29-year time series of North Atlantic groundfish assemblages monitored over 5° latitude to the west of Scotland. These fish assemblages show no systematic change in species richness through time, but steady change in species composition, leading to an increase in spatial homogenization: the species identity of colder northern localities increasingly resembles that of warmer southern localities."*

Steps would be:

1. Calculate Jacard similarity between each haul in a single year in a single region. The vegdist() function in the vegan package would do this,OceanAdapt should have the data you’d need 
https://github.com/pinskylab/OceanAdapt/tree/master/data_raw for NEUS files

1. Calculate geographic distance between each haul in km (e.g., geosphere package in R could work).
1. Plot similarity vs. geographic distance and fit a regression line.
1. Repeat for each year.

A good place to start would just be the Northeast US. We could take a look and then think about expanding out to the other regions and to European data.

Methods from Magurran et al. 

First assign the rectangles to nine 30' latitudinal bands
Compile community time series for each latitudinal band
Sample rarefaction ensures equal sampling effort across bands and is used in the calculation of temporal $\alpha$ diversity and temporal $\beta$ diversity. 
First calculate similarity in relation to the start of the survey
Next, for each year, we compute pairwise compositional similarity of these latitudinal bands
We also construct distance-decay plots for each year

```{r setup}
library(data.table)
library(vegan)
```


```{r import all data from Ocean Adapt}
neus_strata <- read.csv("neus_strata.csv")
save(neus_strata, file = "neus_strata.RData")

load("neus_strata.Rdata")
load("neus_Survdat.RData")
load("neus_SVSPP.RData")

```

```{r extract columns we need from each}
neus_strata.r <- data.table(neus_strata[,c(2:3,5:6)])
neus_survdat.r <- data.table(survdat[,c(3,5,6,8,9, 10, 11)])
neus_spp.r <- data.table(spp[,c(1,2,4)])
```

```{r link data tables together}
stratamerge <- neus_survdat.r[neus_strata.r, on = "STRATUM"]
neus_full <- stratamerge[neus_spp.r, on = "SVSPP"]
neus_full
```

Make sure every observation is of an identifiable fish, aka SVSPP != 0

```{r ID fish}
neus_full.ID <- neus_full[SVSPP != 0,]
```

Group Stratums

For now, I will split into MAB, SNE, GB, and GOM

From Michelle's metadata:

Stratum group code: 
01 = Trawl, offshore north of Hatteras; 
03 = Trawl, inshore north of Hatteras; 
05 = Scotian shelf; 
07 = Trawl, inshore south of Hatteras; 
08 = Trawl, Offshore south of Hatteras;

#we only want 01 and 03's 

```{r only offshore and inshore north of hatteras}
neus_full.ID.0103 <- neus_full.ID[STRATUM < 4000]
```

Region Stratum Key
```{r region stratum key}
region_strata_key <- read.csv("key_reg_strata.csv")
region_strata_key.r <- na.omit(region_strata_key, STRATUM_NAME)
```

```{r link key to neus trawls}
neus_full.ID.regions <- neus_full.ID.0103[region_strata_key.r, on = "STRATUM_NAME"]
```
Find center point of trawls in each region to find distance between regions
```{r center points of trawls }
library(geosphere)
library(rgeos)

latlon_reg <- na.omit(neus_full.ID.regions[,c("LAT", "LON", "reg")])

latlon_reg <- unique(latlon_reg, by = c("LAT", "LON")) # single lat lon for each, to reduce bias

# Define centroid function - Lon is first argument and Lat is second
# Geosphere takes a matrix with two columns: Lon|Lat, so we use cbind to coerce the data to this form
findCentroid <- function(LON, LAT, ...){
  centroid(cbind(LON, LAT), ...)
}

# Find centroid Lon and Lat by ID, as required
latlon_reg[, c("Cent_lon", "Cent_lat") := as.list(findCentroid(LON, LAT)), by = reg]

reg_centroids <- unique(latlon_reg, by = c("Cent_lon", "Cent_lat"))

#reorder so in same order as community matrix below
reg_centroids[, reg := factor(reg, levels = c("GEO", "MAB", "SNE", "GME"))]

setorder(reg_centroids, reg)
```



```{r reduce to simple "yes/no present in this year"}
#one PRESENT value for each YEAR, SEASON, reg, and SVSPP combination
neus_full.ID.regions.unique <- unique(neus_full.ID.regions, by = c("YEAR", "reg", "SVSPP")) #unique mini-region, year, species combinations

#reduce data table to just be svspp, year, sciname, comname, reg

neus_full.ID.regions.unique.r <- data.table(na.omit(neus_full.ID.regions.unique[, c("SVSPP", "SCINAME", "COMNAME", "YEAR", "reg")], col = "YEAR"))

#add presence column 
neus_full.ID.regions.unique.r[,"present" := 1]

#now I need to populate a comparison with every year, region, and species combination to add 0s
reg <- c("GEO", "MAB", "SNE", "GME")
full_set <- data.table(expand.grid("SVSPP" = unique(spp$SVSPP), "YEAR" = unique(neus_full.ID.regions.unique.r$YEAR), "reg" = reg))


```

```{r bring in actual presences to expansion}
merge <- neus_full.ID.regions.unique.r[full_set, on = c("YEAR", "reg", "SVSPP")]
merge[,"present" := ifelse(is.na(SCINAME), 0,1)][,"SCINAME" := NULL][,"COMNAME" := NULL]

#simplify spp key
spp_key <- spp[,c("SCINAME", "SVSPP", "COMNAME")]

neus_pres_abs <- merge[spp_key, on = c("SVSPP")] #also don't actually need all columns


sum(neus_pres_abs$present) #check to make sure we have the right number of presences

```
"To use the package the data have to be in the form of a community matrix.  The basic form is to have the species as columns and the plots as rows."

That is, we’d like to collect all child observations corresponding to each family_id, age_mother together under the same row. We can accomplish it using dcast as follows:

dcast(DT.m1, family_id + age_mother ~ child, value.var = "dob")
#    family_id age_mother dob_child1 dob_child2 dob_child3
# 1:         1         30 1998-11-26 2000-01-29       <NA>
# 2:         2         27 1996-06-22       <NA>       <NA>
# 3:         3         26 2002-07-11 2004-04-05 2007-09-02
# 4:         4         32 2004-10-10 2009-08-27 2012-07-21
# 5:         5         29 2000-12-05 2005-02-28       <NA>

All presence observations corresponding to each species, reg, year under the same row
```{r long to wide}
#1963 is the first year, so we will start there
neus_pres_abs_1year <- neus_pres_abs[YEAR == 1963,]


neus_pres_abs_1year_wide <- dcast(neus_pres_abs_1year, YEAR + reg ~ SVSPP, value.var = "present")
```


```{r jaccard dissimiliarities between regions in one year}

#to make vegdist work, each year-reg combination needs to be a "plot#"
#I'll do this super simply here
plot <- data.table("plot" = c(1:4))

neus_pres_abs_1year_wide.communitymatrix <- cbind(plot, neus_pres_abs_1year_wide[,c(3:820)], neus_pres_abs_1year_wide[,c(1:2)])

similarities_1963 <- vegdist(neus_pres_abs_1year_wide.communitymatrix[,c(1:819)], method = "jaccard") #similarity matrix for 1963

reg_centroids_plots <- cbind(plot, reg_centroids)

reg_centroid_key <- reg_centroids_plots[, c(1, 4, 5, 6)]

reg_distances <- dist(reg_centroid_key[,c(1, 3, 4)], diag = T, upper = T)

reg_distances <- distm(reg_centroid_key[,c(3, 4)]) #distance matrix, consistent across years
rownames(reg_distances) <- reg_centroid_key$plot
colnames(reg_distances) <- reg_centroid_key$plot

?distm
```
```{r matrices wide to long form}
library(reshape2)

reg_distance.l <- melt(as.matrix(reg_distances), varnames = c("reg1", "reg2")) #matrix to data frame

  
  
```

```{r jaccard dissimilarities between regions in multiple years}

```

