---
title: "SHELF_similarity_heatmap_distance"
output: html_notebook
---

```{r setup}
library(data.table)
library(viridis)
library(ggplot2)
library(reshape2)
library(geosphere)
library(vegan)
library(raster)
library(here)
library(cowplot)
library(plyr)

#load data
dat_SHELF_grid.reduced_3plustows <- readRDS("/Users/zoekitchel/Documents/grad school/Rutgers/Repositories/trawl_spatial_turnover/data/gridded/USA-SHELF/dat_SHELF_grid.reduced_3plustows.rds")

#distance among grid cells

shelf_reg_distances.l <- readRDS("/Users/zoekitchel/Documents/grad school/Rutgers/Repositories/trawl_spatial_turnover/data/gridded/USA-SHELF/shelf_reg_distances.l.rds")
```

Region Stats

* Number of species in region
* Length of study period
* Number of years in which data was collected
* Range of latitudes sampled
* Mid latitude of region
* Range of longitudes sampled
* Overall area sampled
* Depths sampled

```{r region stats}
shelf_stats <- data.table(region = character() , season = character(), spp_num = numeric(), study_period = numeric(), study_duration = numeric(), lat_range = numeric(), mid_lat = numeric(), lon_range = numeric(), area = numeric(), depth_range = numeric(),  mid_depth = numeric())


#maps
####unique lat lon
shelf_lat_lon <- unique(dat_SHELF_grid.reduced_3plustows[,.(latitude, longitude)])

shelf_pts <- st_as_sf(shelf_lat_lon, coords=c('longitude','latitude'), crs=4326 )

shelf_conc <- concaveman(shelf_pts)

shelf_area <- st_area(shelf_conc) #m2

#row
shelf <- c("shelf","NA",length(unique(dat_SHELF_grid.reduced_3plustows$accepted_name)),
               max(dat_SHELF_grid.reduced_3plustows$year)-min(dat_SHELF_grid.reduced_3plustows$year),
               length(unique(dat_SHELF_grid.reduced_3plustows$year)),
               max(dat_SHELF_grid.reduced_3plustows$latitude)-min(dat_SHELF_grid.reduced_3plustows$latitude),
               mean(dat_SHELF_grid.reduced_3plustows$latitude),
               max(dat_SHELF_grid.reduced_3plustows$longitude)-min(dat_SHELF_grid.reduced_3plustows$longitude),
               shelf_area,
               max(dat_SHELF_grid.reduced_3plustows$depth, na.rm = T)-min(dat_SHELF_grid.reduced_3plustows$depth, na.rm = T),
               mean(dat_SHELF_grid.reduced_3plustows$depth, na.rm = T)
               )



shelf_stats <- data.table(rbind(shelf))

colnames(shelf_stats)<-c("region","season","spp_num","study_period","study_duration","lat_range","mid_lat","lon_range","area","depth_range","mid_depth")

```


Lists of Years
```{r year lists}
dat_SHELF_grid.reduced_3plustows[,year:= as.numeric(year)] #make numeric
setorder(dat_SHELF_grid.reduced_3plustows, year)

shelf_years <- unique(dat_SHELF_grid.reduced_3plustows[,year])

```

Haul ID keys
```{r list of haul_ids}
shelf_haul_ids <- unique(dat_SHELF_grid.reduced_3plustows[,haul_id])
shelf_haul_ids_key <- data.table(haul_id = shelf_haul_ids, key_ID = seq(1,length(shelf_haul_ids), by = 1))

```

Convert haul_ids to numeric key_IDs
```{r}

dat_SHELF_grid.reduced_3plustows <- dat_SHELF_grid.reduced_3plustows[shelf_haul_ids_key, on = "haul_id"]

```


Dissimilarities across multiple years

```{r dissimilarities between cells across multiple years for spring}
library(betapart) 
shelf_distances_dissimilarities_allyears <- data.table("haul_id1" = integer(), "haul_id2" = integer(), "distance" = numeric(),"bray_curtis_dissimilarity_balanced" = numeric(), year = integer(), "jaccard_dissimilarity_turnover" = numeric())

#Now loop through all years
for (i in 1:length(shelf_years)) {
  reduced_year <- dat_SHELF_grid.reduced_3plustows[year == shelf_years[i],]
  
#cannot have wgt or num
  reduced_year <- reduced_year[!is.na(wgt_cpue),]
  
  #distances among cells
  setorder(reduced_year, key_ID)
  
  latitude_longitude_haul_id <- unique(reduced_year[,.(latitude,longitude,key_ID)])
  shelf_distances <- distm(latitude_longitude_haul_id[,.(longitude,latitude)])
  key_IDs <- latitude_longitude_haul_id[,key_ID]

  colnames(shelf_distances) <- rownames(shelf_distances) <- key_IDs

  #wide to longitudeg
  haul_id_distances.l <- reshape2::melt(shelf_distances,varnames = (c("haul_id1", "haul_id2")), value.name = "distance")
  
  #make into data table
  haul_id_distances.l <- data.table(haul_id_distances.l)

  
  reduced_year_wide <- dcast(reduced_year, key_ID + year ~ accepted_name, value.var = "wgt_cpue", fun.aggregate = sum) #longitude to wide data for community matrix, column names are cell then species
  
  
  ncols <- ncol(reduced_year_wide)
  communitymatrix <- reduced_year_wide[,3:ncols] #community matrix with year and cell on far right
  communitymatrix.occurence <- communitymatrix
  communitymatrix.occurence[communitymatrix.occurence > 0] <- 1

  #list of haul_id keys
  key_IDs_subset <- reduced_year_wide$key_ID

  dissimilarities_abundance <- beta.pair.abund(communitymatrix, index.family = "bray") #dissimilarity 
  dissimilarities_occurrence <- beta.pair(communitymatrix.occurence, index.family = "jaccard") #dissimilarity

  #make into matrix
  dissimilarities_abundance.m <- as.matrix(dissimilarities_abundance$beta.bray.bal, labels=TRUE) #bal = balanced
  dissimilarities_occurrence.m <- as.matrix(dissimilarities_occurrence$beta.jtu, labels=TRUE) #jtu = turnover
  colnames(dissimilarities_abundance.m) <- rownames(dissimilarities_abundance.m) <- key_IDs_subset
  colnames(dissimilarities_occurrence.m) <- rownames(dissimilarities_occurrence.m) <- key_IDs_subset

  #reshape dissimilarities
  dissimilarities_abundance.l <- reshape2::melt(dissimilarities_abundance.m, varnames = c("haul_id1", "haul_id2"), value.name = "bray_curtis_dissimilarity_balanced")
  dissimilarities_occurrence.l <- reshape2::melt(dissimilarities_occurrence.m, varnames = c("haul_id1", "haul_id2"), value.name = "jaccard_dissimilarity_turnover")
  dissimilarities_abundance.l <- data.table(dissimilarities_abundance.l) #and then to data table
  dissimilarities_occurrence.l <- data.table(dissimilarities_occurrence.l)

  #add year for these values
  dissimilarities_abundance.l[, "year" := shelf_years[i]]
  dissimilarities_occurrence.l[, "year" := shelf_years[i]]

  #merge distance with dissimilarity for this year with both metrics of dissimilarity
  dissimilarities_full <- haul_id_distances.l[dissimilarities_abundance.l, on = c("haul_id1", "haul_id2")]
  dissimilarities_full <- dissimilarities_full[dissimilarities_occurrence.l, on = c("haul_id1", "haul_id2", "year")]


  #add to data table
  shelf_distances_dissimilarities_allyears <- rbind(shelf_distances_dissimilarities_allyears, dissimilarities_full)
  
  print(paste0(i,"/",length(shelf_years)))
  
}

summary(shelf_distances_dissimilarities_allyears) #here we have bray, jaccard and geographic distance

#delete repeats
shelf_distances_dissimilarities_allyears <- shelf_distances_dissimilarities_allyears[haul_id1 >= haul_id2,]


shelf_distances_dissimilarities_allyears[,bray_curtis_similarity_balanced := (1-bray_curtis_dissimilarity_balanced)][,jaccard_similarity_turnover := (1-jaccard_dissimilarity_turnover)]

saveRDS(shelf_distances_dissimilarities_allyears, file = "shelf_distances_dissimilarities_allyears.rds")

shelf_distances_dissimilarities_allyears <- readRDS("shelf_distances_dissimilarities_allyears.rds")

```

#Heat map

Subsample for plotting

#try rounding to 10s and 1s this time!
```{r subsample}
#jaccard only
shelf_distances_dissimilarities_allyears_jaccard <- shelf_distances_dissimilarities_allyears[,.(year,distance,jaccard_similarity_turnover, bray_curtis_similarity_balanced)][,distance_km := distance/1000]

#new column with rounded distance
shelf_distances_dissimilarities_allyears_jaccard[,distance_km_10s := round_any(distance_km,10)][,distance_km_1s := round(distance_km,0)] #round to nearest 10, 1

#new column with median jaccard similarity & bray similarity meapt for 1 and 10 km
shelf_distances_dissimilarities_allyears_jaccard[, jaccard_similarity_mean_10s := 
                                                       mean(jaccard_similarity_turnover), .(year, distance_km_10s)][, bray_similarity_mean_10s :=
                                                      mean(bray_curtis_similarity_balanced), .(year, distance_km_1s)][, jaccard_similarity_mean_1s := 
                                                       mean(jaccard_similarity_turnover), .(year, distance_km_1s)][, bray_similarity_mean_1s :=
                                                      mean(bray_curtis_similarity_balanced), .(year, distance_km_1s)]

#reduce to unique values
shelf_distances_dissimilarities_allyears_jaccard_rounded <- unique(shelf_distances_dissimilarities_allyears_jaccard, by = c("year","distance_km_10s","distance_km_1s"))
```

All possible combos
```{r all combos}
#all possible 1s
seq_1 <- seq(0,max(shelf_distances_dissimilarities_allyears_jaccard_rounded$distance_km_1s), by = 1)

#all possible 10s
seq_10 <- seq(0,max(shelf_distances_dissimilarities_allyears_jaccard_rounded$distance_km_10s), by = 10)

#datatable with all possible combos
shelf_distances_dissimilarities_allyears_jaccard_allcombos <- data.table(expand.grid(year = shelf_years, distance_km_1s = seq_1))

#combine
shelf_distances_dissimilarities_allyears_jaccard_rounded_allcombos <- shelf_distances_dissimilarities_allyears_jaccard_allcombos[shelf_distances_dissimilarities_allyears_jaccard_rounded, on = c("year","distance_km_1s")]

```

From "Depth-Time visualization using R, the tidyverse, and ggplot2" tutorial

```{r plot heat maps}

#convert year to factor
setkey(shelf_distances_dissimilarities_allyears,year)
shelf_distances_dissimilarities_allyears[,year.f := as.factor(year)]

#save this data table
saveRDS(shelf_distances_dissimilarities_allyears_jaccard_rounded_allcombos, here::here("output","distance_decay","shelf_distances_dissimilarities_allyears_jaccard_rounded_allcombos.rds"))


#jaccard similarity
(shelf_jaccard_heatmap <- ggplot(shelf_distances_dissimilarities_allyears_jaccard_rounded_allcombos,aes(as.factor(year),distance_km_1s, color = jaccard_similarity_mean_1s)) +
  geom_point(shape = 95, size = 1) +
  scale_color_gradientn(colors =
c("purple" ,"cornflowerblue", "green" , "yellow" ,"orange", "red")
  ) +
scale_x_discrete(limits=levels(shelf_distances_dissimilarities_allyears_jaccard_rounded_allcombos$year.f), breaks = c("1984", "1990", "1995", "2000", "2005", "2010","2015")) +
  labs(y = "Distance (km)", x = "Year", color = "Jaccard Similarity") +
  theme_classic())

ggsave(plot = shelf_jaccard_heatmap, path = here::here("figures","shelf"),file = "shelf_jaccard_heatmap.jpg")
ggsave(plot = shelf_jaccard_heatmap, path = here::here("figures","shelf"),file = "shelf_jaccard_heatmap.eps")


#bray curtis similarity
(shelf_bray_heatmap <- ggplot(shelf_distances_dissimilarities_allyears_jaccard_rounded_allcombos,aes(as.factor(year),distance_km_1s, color = bray_similarity_mean_1s)) +
  geom_point(shape = 95, size = 1) +
  scale_color_gradientn(colors =
c("purple" ,"cornflowerblue", "green" , "yellow" ,"orange", "red")
  ) +
  scale_x_discrete(limits=levels(shelf_distances_dissimilarities_allyears_jaccard_rounded_allcombos$year.f), breaks = c("1984", "1990", "1995", "2000", "2005", "2010","2015")) +
  labs(y = "Distance (km)", x = "Year", color = "Bray Curtis Similarity") +
  theme_classic())

ggsave(plot = shelf_bray_heatmap, path = here::here("figures","shelf"),file = "shelf_bray_heatmap.jpg")
ggsave(plot = shelf_bray_heatmap, path = here::here("figures","shelf"),file = "shelf_bray_heatmap.eps")
```
Box plots
```{r spring box plots}

#jaccard similarity
(shelf_jaccard_boxplot <- ggplot(shelf_distances_dissimilarities_allyears,aes(year.f,jaccard_similarity_turnover)) +
  geom_boxplot(outlier.shape = NA, lwd = 0.2) +
  labs(x="Year", y = "Jaccard Similarity") +
  scale_x_discrete(limits=levels(shelf_distances_dissimilarities_allyears$year.f), breaks = c("1984", "1990", "1995", "2000", "2005", "2010","2015")) +
  geom_smooth(method = "lm", se=FALSE, color="red", aes(group=1), lwd = 0.3) +
  stat_regline_equation(label.x = 3, label.y = 32) +
  ylim(c(0,0.68)) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90)))

#bray curtis similarity
(shelf_bray_boxplot <- ggplot(shelf_distances_dissimilarities_allyears,aes(year.f,bray_curtis_similarity_balanced)) +
  geom_boxplot(outlier.shape = NA, lwd = 0.2) +
  labs(x="Year", y = "Bray Curtis Similarity") +
  scale_x_discrete(limits=levels(shelf_distances_dissimilarities_allyears$year.f), breaks = c("1984", "1990", "1995", "2000", "2005", "2010","2015")) +
  geom_smooth(method = "lm", se=FALSE, color="red", aes(group=1), lwd = 0.3) +
  stat_regline_equation(label.x = 3, label.y = 32) +
    ylim(c(0,0.48)) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90)))

#corresponding models
shelf_avg_jaccard_mod <- lm(data = shelf_distances_dissimilarities_allyears, formula = jaccard_similarity_turnover ~ as.numeric(year))

shelf_avg_bray_curtis_mod <- lm(data = shelf_distances_dissimilarities_allyears, formula = bray_curtis_similarity_balanced ~ as.numeric(year))

summary(shelf_avg_jaccard_mod)
summary(shelf_avg_bray_curtis_mod)
```

Now, merge the previous two plots
```{r merge plots}
#pull out legend
shelf_legend_heatmaps <- get_legend(shelf_jaccard_heatmap + labs(color = "Similarity"))

shelf_merge <- plot_grid(shelf_jaccard_heatmap + theme(legend.position = "none", axis.title.x = element_blank(), axis.text.x = element_blank()) ,
                       shelf_bray_heatmap + theme(legend.position = "none", axis.title.x = element_blank(), axis.text.x = element_blank(), axis.title.y = element_blank()),
                    #   shelf_legend_heatmaps,
                       shelf_jaccard_boxplot, shelf_bray_boxplot,  nrow = 2, ncol = 2, align = "hv", axis = "lb")

shelf_merge

ggsave(shelf_merge, path = here::here("figures","shelf"), file = "shelf_heat_boxplot_merge.jpg", width = 6, height = 5, unit = "in")
ggsave(shelf_merge, path = here::here("figures","shelf"), file = "shelf_heat_boxplot_merge.eps", width = 6, height = 5, unit = "in")

```

Add extra columns with coefficients
```{r data summary with coef}

shelf_stats[,jac_coef := 
           shelf_avg_jaccard_mod$coefficients[[2]]][, jac_p := 
          summary(shelf_avg_jaccard_mod)$coefficients[2,4]][,bray_coef :=
          shelf_avg_bray_curtis_mod$coefficients[[2]]][,bray.p := 
          summary(shelf_avg_bray_curtis_mod)$coefficients[2,4]]


saveRDS(shelf_stats, here::here("output","region_stats","shelf_stats.rds"))
```








###maybe i'll do this later? maybe not
At its heart, this graphic is just a ggplot() with a geom_raster() layer. The complication is, geom_raster() requires equally spaced points in both the x- and y-direction. The rest of this post is about how to make that happen.

Linear Interpolation

I interpolate in the distance direction first, because I think this is the better assumption: as you go down further away, a reasonable way to estimate the similarity at a distance which you did not measure is to draw a straight line between the similarity at the distance that you did measure. (Not great, but sure)
```{r}
estimate_jac_sim_by_year <- function(target_year, target_distance) {
  data_for_year <- shelf_distances_dissimilarities_allyears[year == target_year]
  
  # approx() is one way to do a linear interpolation
  approx(data_for_year$distance, data_for_year$jaccard_similarity, xout = target_distance)$y
}

estimate_jac_sim_by_year(1990, c(0,3000,300000))
```
Expand data inputs
```{r}
temp_interp_depth <- data.table(expand.grid(
  # the same years as shelf spring
  year = shelf_years,
  # ddistances can now be any value
  distance = seq(0, max(shelf_distances_dissimilarities_allyears$distance), by = 10))
)

temp_interp_depth[,jaccard_similarity_modeled := estimate_jac_sim_by_year(year,distance), year]

```
Visualize
```{r}
ggplot(temp_interp_depth,aes(year,distance, color = jaccard_similarity_modeled)) +
  geom_point() +
   scale_colour_gradient2(
    midpoint = 0.5, 
    high = scales::muted("red"), 
    low = scales::muted("blue")
  )
```

First, we write a function that estimates the temperature at any date given a depth that is in temp_interp_depth (the tibble we just calculated).

```{r}
estimate_jac_sim_by_distance <- function(target_distance, target_year) {
  data_for_distance <- temp_interp_depth[distance == target_distance,]
    setkey(data_for_distance, year)
  approx(data_for_distance$year, data_for_distance$jaccard_similarity_modeled, xout = target_year)$y
}

estimate_jac_sim_by_distance(
  target_distance = 1000000, 
  target_year = c(1990,1998,2000)
)
```
Expand year grid
```{r}
jac_sim_raster <- data.table(expand.grid(
  # dates can now be any value
  year = seq(min(shelf_years), max(shelf_years), by = 1),
  # depths must be the same as in temp_interp_depth
  distance = unique(temp_interp_depth$distance))
)

jac_sim_raster[,jaccard_similarity_modeled := estimate_jac_sim_by_distance(distance,year),by = distance]


```
Finally, we have equally-spaced values in both the date and depth dimensions. This can be visualized using geom_raster(), with temp mapped to the fill aesthetic. I’ve again used scale_fill_gradient2() to ensure that red values represent “hot”, blue values represent “cool”, and that there is some way to visualize the depth of the thermocline. Finally, I’ve used coord_cartesian(expand = FALSE) to eliminate the white border around the outside of the raster layer…I think it looks nicer that way.


```{r final jaccard similarity plot}
ggplot(jac_sim_raster, aes(year, distance, fill = jaccard_similarity_modeled)) +
  geom_raster() +
  scale_fill_gradientn(colors =
c("purple" ,"blue"  , "green" , "yellow" ,"orange", "red")
  ) +
  coord_cartesian(expand = FALSE)
```


                 