---
title: "AI_similarity_heatmap_distance"
output: html_notebook
---

```{r setup}
library(data.table)
library(viridis)
library(ggplot2)
library(reshape2)
library(geosphere)
library(vegan)
library(raster)
library(here)
library(cowplot)

#load data
dat_AI_grid.reduced_3plustows <- readRDS("/Users/zoekitchel/Documents/grad school/Rutgers/Repositories/trawl_spatial_turnover/data/gridded/USA-AI/dat_ai_grid.reduced_3plustows.rds")

#distance among grid cells

ai_reg_distances.l <- readRDS("/Users/zoekitchel/Documents/grad school/Rutgers/Repositories/trawl_spatial_turnover/data/gridded/USA-AI/dat_ai_reg_distances.l.rds")
```
Lists of Years
```{r year lists}
dat_AI_grid.reduced_3plustows[,year:= as.numeric(year)] #make numeric
setorder(dat_AI_grid.reduced_3plustows, year)

ai_years <- unique(dat_AI_grid.reduced_3plustows[,year])
```

Haul ID keys
```{r list of haul_ids}
ai_haul_ids <- unique(dat_AI_grid.reduced_3plustows[,haul_id])
ai_haul_ids_key <- data.table(haul_id = ai_haul_ids, key_ID = seq(1,length(ai_haul_ids), by = 1))

```

Convert haul_ids to numeric key_IDs
```{r}
#fall
dat_AI_grid.reduced_3plustows <- dat_AI_grid.reduced_3plustows[ai_haul_ids_key, on = "haul_id"]

```


Dissimilarities across multiple years
fall
```{r dissimilarities between cells across multiple years}
ai_distances_dissimilarities_allyears <- data.table("haul_id1" = integer(), "haul_id2" = integer(), "distance" = numeric(),"bray_curtis_dissimilarity" = numeric(), year = integer(), "jaccard_dissimilarity" = numeric())

#Now loop through all years
for (i in 1:length(ai_years)) {
  reduced_year <- dat_AI_grid.reduced_3plustows[year == ai_years[i],]
  
  #distances among cells
  setorder(reduced_year, key_ID)
  
  lat_lon_haul_id <- unique(reduced_year[,.(latitude,longitude,key_ID)])
  ai_distances <- distm(lat_lon_haul_id[,.(longitude,latitude)])
  key_IDs <- lat_lon_haul_id[,key_ID]

  colnames(ai_distances) <- rownames(ai_distances) <- key_IDs

  #wide to long
  haul_id_distances.l <- reshape2::melt(ai_distances,varnames = (c("haul_id1", "haul_id2")), value.name = "distance")
  
  #make into data table
  haul_id_distances.l <- data.table(haul_id_distances.l)

  
  reduced_year_wide <- dcast(reduced_year, key_ID + year ~ accepted_name, value.var = "wgt_cpue", fun.aggregate = sum) #long to wide data for community matrix, column names are cell then species
  
  ncols <- ncol(reduced_year_wide)
  communitymatrix <- cbind(reduced_year_wide[,3:ncols], reduced_year_wide[,1:2]) #community matrix with year and cell on far right

  #list of haul_id keys
  key_IDs_subset <- communitymatrix$key_ID

  dissimilarities_abundance <- vegdist(communitymatrix[,1:(ncols-2)], method = "bray", binary = F) #dissimilarity 
  dissimilarities_occurrence <- vegdist(communitymatrix[,1:(ncols-2)], method = "jaccard", binary = T) #T binary performs presence absence standardization before using decostand

  #make into matrix
  dissimilarities_abundance.m <- as.matrix(dissimilarities_abundance, labels=TRUE)
  dissimilarities_occurrence.m <- as.matrix(dissimilarities_occurrence, labels=TRUE)
  colnames(dissimilarities_abundance.m) <- rownames(dissimilarities_abundance.m) <- key_IDs_subset
  colnames(dissimilarities_occurrence.m) <- rownames(dissimilarities_occurrence.m) <- key_IDs_subset

  #reshape dissimilarities
  dissimilarities_abundance.l <- reshape2::melt(dissimilarities_abundance.m, varnames = c("haul_id1", "haul_id2"), value.name = "bray_curtis_dissimilarity")
  dissimilarities_occurrence.l <- reshape2::melt(dissimilarities_occurrence.m, varnames = c("haul_id1", "haul_id2"), value.name = "jaccard_dissimilarity")
  dissimilarities_abundance.l <- data.table(dissimilarities_abundance.l) #and then to data table
  dissimilarities_occurrence.l <- data.table(dissimilarities_occurrence.l)

  #add year for these values
  dissimilarities_abundance.l[, "year" := ai_years[i]]
  dissimilarities_occurrence.l[, "year" := ai_years[i]]

  #merge distance with dissimilarity for this year with both metrics of dissimilarity
  dissimilarities_full <- haul_id_distances.l[dissimilarities_abundance.l, on = c("haul_id1", "haul_id2")]
  dissimilarities_full <- dissimilarities_full[dissimilarities_occurrence.l, on = c("haul_id1", "haul_id2", "year")]


  #add to data table
  ai_distances_dissimilarities_allyears <- rbind(ai_distances_dissimilarities_allyears, dissimilarities_full)
  
}

summary(ai_distances_dissimilarities_allyears) #here we have bray, jaccard and geographic distance

#delete repeats
ai_distances_dissimilarities_allyears <- ai_distances_dissimilarities_allyears[haul_id1 >= haul_id2,] #3165272 to 1588479 rows


ai_distances_dissimilarities_allyears[,bray_curtis_similarity := (1-bray_curtis_dissimilarity)][,jaccard_similarity := (1-jaccard_dissimilarity)]

saveRDS(ai_distances_dissimilarities_allyears, file = "ai_distances_dissimilarities_allyears.rds")

ai_distances_dissimilarities_allyears <- readRDS("ai_distances_dissimilarities_allyears.rds")

```

#Heat map

Subsample for plotting
```{r subsample}
#jaccard only
ai_distances_dissimilarities_allyears_jaccard <- ai_distances_dissimilarities_allyears[,.(year,distance,jaccard_similarity)]

#new column with rounded distance
ai_distances_dissimilarities_allyears_jaccard[,distance_10s := round(distance,-1)] #round to nearest 100

#new column with median jaccard similarity
ai_distances_dissimilarities_allyears_jaccard[, jaccard_similarity_mean := mean(jaccard_similarity), .(year, distance_10s)]

#reduce to unique values
ai_distances_dissimilarities_allyears_jaccard_rounded <- unique(ai_distances_dissimilarities_allyears_jaccard, by = c("year","distance_10s"))
```


All possible combos
```{r all combos}
#all possible 10s
seq_10 <- seq(0,max(ai_distances_dissimilarities_allyears_jaccard_rounded$distance_10s), by = 10)

#datatable with all possible combos
ai_distances_dissimilarities_allyears_jaccard_allcombos <- data.table(expand.grid(year = ai_years, distance_10s = seq_10))

#make sure year is numeric
ai_distances_dissimilarities_allyears_jaccard_rounded[,year:=as.numeric(year)]

#combine
ai_distances_dissimilarities_allyears_jaccard_rounded_allcombos <- ai_distances_dissimilarities_allyears_jaccard_allcombos[ai_distances_dissimilarities_allyears_jaccard_rounded, on = c("year","distance_10s")]
```


Trying to use ggplot
```{r}
ggplot(ai_distances_dissimilarities_allyears_jaccard_rounded_allcombos, aes(year, distance_10s, fill = jaccard_similarity_mean)) +
  geom_raster(interpolate = T) +
  theme_classic() +
  scale_fill_viridis(discrete = F)

library(sp)

```

Convert to matrix
```{r jaccard matrix}
ai_distances_dissimilarities_allyears_jaccard_wide <-
data.table::dcast(ai_distances_dissimilarities_allyears_jaccard_rounded[,.(year,distance_10s,jaccard_similarity_mean)], distance_10s ~ year, fill = NA)

setkey(ai_distances_dissimilarities_allyears_jaccard_wide, distance_10s)

#get rid of first column
ai_distances_dissimilarities_allyears_jaccard_wide.m <- ai_distances_dissimilarities_allyears_jaccard_wide[,2:ncol(ai_distances_dissimilarities_allyears_jaccard_wide)]

ai_distances_dissimilarities_allyears_jaccard_wide.m <- as.matrix(ai_distances_dissimilarities_allyears_jaccard_wide.m)

ai_distances_dissimilarities_allyears_jaccard_wide.r <- as.raster (ai_distances_dissimilarities_allyears_jaccard_wide.m)
```

Convert comprehensive table to matrix
```{r}
ai_distances_dissimilarities_allyears_jaccard_rounded_allcombos_wide <- data.table::dcast(ai_distances_dissimilarities_allyears_jaccard_rounded_allcombos[,.(year,distance_10s,jaccard_similarity_mean)], distance_10s ~ year, fill = NA)

setkey(ai_distances_dissimilarities_allyears_jaccard_rounded_allcombos_wide, distance_10s)

#get rid of first column
ai_distances_dissimilarities_allyears_jaccard_rounded_allcombos_wide.m <- ai_distances_dissimilarities_allyears_jaccard_rounded_allcombos_wide[,2:ncol(ai_distances_dissimilarities_allyears_jaccard_rounded_allcombos_wide)]

ai_distances_dissimilarities_allyears_jaccard_rounded_allcombos_wide.m <- as.matrix(ai_distances_dissimilarities_allyears_jaccard_rounded_allcombos_wide.m)

ai_distances_dissimilarities_allyears_jaccard_rounded_allcombos_wide.r <- as.raster (ai_distances_dissimilarities_allyears_jaccard_rounded_allcombos_wide.m)
```

From "Depth-Time visualization using R, the tidyverse, and ggplot2" tutorial

```{r plot heat maps}

#convert year to factor
setkey(ai_distances_dissimilarities_allyears,year)
ai_distances_dissimilarities_allyears[,year.f := as.factor(year)]

#jaccard similarity
ai_jaccard_heatmap <- ggplot(ai_distances_dissimilarities_allyears,aes(as.factor(year),distance/1000, color = jaccard_similarity)) +
  geom_point(shape = 15, size = 0.7) +
  scale_color_gradientn(colors =
c("purple" ,"cornflowerblue", "green" , "yellow" ,"orange", "red")
  ) +
scale_x_discrete(limits=levels(ai_distances_dissimilarities_allyears$year.f), breaks = c("1983", "1990", "1995", "2000", "2005", "2010","2015")) +
  labs(y = "Distance (km)", x = "Year", color = "Jaccard Similarity") +
  theme_classic()

ggsave(plot = ai_jaccard_heatmap, path = here::here("figures","ai"),file = "ai_jaccard_heatmap.jpg")
ggsave(plot = ai_jaccard_heatmap, path = here::here("figures","ai"),file = "ai_jaccard_heatmap.eps")


#bray curtis similarity
ai_bray_heatmap <- ggplot(ai_distances_dissimilarities_allyears,aes(as.factor(year),distance/1000, color = bray_curtis_similarity)) +
  geom_point(shape = 15, size = 0.7) +
  scale_color_gradientn(colors =
c("purple" ,"cornflowerblue", "green" , "yellow" ,"orange", "red")
  ) +
  scale_x_discrete(limits=levels(ai_distances_dissimilarities_allyears$year.f), breaks = c("1983", "1990", "1995", "2000", "2005", "2010","2015")) +
  labs(y = "Distance (km)", x = "Year", color = "Bray Curtis Similarity") +
  theme_classic()

ggsave(plot = ai_bray_heatmap, path = here::here("figures","ai"),file = "ai_bray_heatmap.jpg")
ggsave(plot = ai_bray_heatmap, path = here::here("figures","ai"),file = "ai_bray_heatmap.eps")
```
Box plots
```{r fall box plots}

#jaccard similarity
(ai_jaccard_boxplot <- ggplot(ai_distances_dissimilarities_allyears,aes(year.f,jaccard_similarity)) +
  geom_boxplot(outlier.shape = NA, lwd = 0.2) +
  labs(x="Year", y = "Jaccard Similarity") +
  scale_x_discrete(limits=levels(ai_distances_dissimilarities_allyears$year.f), breaks = c("1983", "1990", "1995", "2000", "2005", "2010","2015")) +
  geom_smooth(method = "lm", se=FALSE, color="red", aes(group=1), lwd = 0.3) +
  ylim(c(0,0.68)) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90)))

#bray curtis similarity
(ai_bray_boxplot <- ggplot(ai_distances_dissimilarities_allyears,aes(year.f,bray_curtis_similarity)) +
  geom_boxplot(outlier.shape = NA, lwd = 0.2) +
  labs(x="Year", y = "Bray Curtis Similarity") +
  scale_x_discrete(limits=levels(ai_distances_dissimilarities_allyears$year.f), breaks = c("1983", "1990", "1995", "2000", "2005", "2010","2015")) +
  geom_smooth(method = "lm", se=FALSE, color="red", aes(group=1), lwd = 0.3) +
    ylim(c(0,0.48)) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90)))

#corresponding models
ai_avg_jaccard_mod <- lm(data = ai_distances_dissimilarities_allyears, formula = jaccard_similarity ~ as.numeric(year))

ai_avg_bray_curtis_mod <- lm(data = ai_distances_dissimilarities_allyears, formula = bray_curtis_similarity ~ as.numeric(year))

summary(ai_avg_jaccard_mod)
summary(ai_avg_bray_curtis_mod)
```

Now, merge the previous two plots
```{r merge plots}
#pull out legend
ai_legend_heatmaps <- get_legend(ai_jaccard_heatmap + labs(color = "Similarity"))

ai_merge <- plot_grid(ai_jaccard_heatmap + theme(legend.position = "none", axis.title.x = element_blank(), axis.text.x = element_blank())
                       , ai_bray_heatmap + theme(legend.position = "none", axis.title.x = element_blank(), axis.text.x = element_blank(), axis.title.y = element_blank()),
                       ai_jaccard_boxplot,
                       ai_bray_boxplot,  nrow = 2, ncol = 2, align = "hv", axis = "lb")


ggsave(ai_merge, path = here::here("figures","ai"), file = "ai_heat_boxplot_merge.jpg", width = 3, height = 5, unit = "in")
ggsave(ai_merge, path = here::here("figures","ai"), file = "ai_heat_boxplot_merge.eps", width = 3, height = 5, unit = "in")

```

