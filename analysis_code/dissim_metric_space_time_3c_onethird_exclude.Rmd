---
title: "Calculating Dissimilarity Metrics Across Space and Time for species present at least 1/3 of timeseries for each survey"
output: html_notebook
author: ZoÃ« J. Kitchel
date: October 11, 2023
---

Script 3c for Kitchel et al. 2023 in prep taxonomic diversity manuscript.

```{r setup}
library(data.table)
library(vegan)
library(sf)
library(concaveman) #polygon around points
library(betapart) #allows us to partition beta diversity
library(geosphere)
library(ggpubr) #stat_regline_equation
library(nlme)


FishGlob_clean <- readRDS(here::here("data", "cleaned", "FishGlob_clean.rds"))


```

Loop through all regions (takes  a few hours to run)

```{r list of all survey season combinations}
all_survey_unit <- unique(FishGlob_clean[, survey_unit])
```

Delete any species that are not present in at least 1/3 of years in time series.
```{r}

#unique year, survey, species combinations to identify total # of years for each survey, and total # of years a given species appears
unique_year_survey_spp <- unique(FishGlob_clean[,.(accepted_name, year, survey_unit)])

unique_year_survey_spp[,years_sampled_survey := uniqueN(year),survey_unit][,years_spp_occurs := .N,.(accepted_name, survey_unit)][,perc_occurence := round(years_spp_occurs/years_sampled_survey,2)][,keep_drop := ifelse(perc_occurence>=0.3333,T,F)]

keep_drop_key <- unique(unique_year_survey_spp[,.(accepted_name, survey_unit,keep_drop)])

FishGlob_clean_onethird <- keep_drop_key[FishGlob_clean, on = .(survey_unit, accepted_name)]

FishGlob_clean_onethird_excluded <- FishGlob_clean_onethird[keep_drop == T,]

#drops 
nrow(FishGlob_clean)-nrow(FishGlob_clean_onethird_excluded)
#14155/2731535 rows (0.4% of observations)
```

Table listing species included in each region and then those excluded for 15% least common species analyses.
```{r}
FishGlob_clean_15perc_excluded <- readRDS(here::here("output","FishGlob_clean_15perc_excluded.Rds"))

survey_unit_spp_list <- list()
for (i in 1:length(all_survey_units)) {
  survey_unit_spp_list[i] <- list(sort(unique(FishGlob_clean[survey_unit == all_survey_units[i], accepted_name])))
}

names(survey_unit_spp_list) <- paste0(all_survey_units, " full species list")

#spp excluded for 15%
survey_unit_spp_list_excluded_15perc <- list()
for (i in 1:length(all_survey_units)) {
  full_spp <- unique(FishGlob_clean[survey_unit == all_survey_units[i],]$accepted_name)
  spp_15perc <- unique(FishGlob_clean_15perc_excluded[survey_unit == all_survey_units[i],]$accepted_name)
  survey_unit_spp_list_excluded_15perc[i] <- list(sort(setdiff(full_spp, spp_15perc)))
}

names(survey_unit_spp_list_excluded_15perc) <- paste0(all_survey_units,", exclude lowest 15% abundance")

#spp excluded for 1/3 occurence

survey_unit_spp_list_excluded_onethird <- list()
for (i in 1:length(all_survey_units)) {
  full_spp <- unique(FishGlob_clean[survey_unit == all_survey_units[i],]$accepted_name)
  spp_onethirdexclude <- unique(FishGlob_clean_onethird_excluded[survey_unit == all_survey_units[i],]$accepted_name)
  survey_unit_spp_list_excluded_onethird[i] <- list(sort(setdiff(full_spp, spp_onethirdexclude)))
}

names(survey_unit_spp_list_excluded_onethird) <- paste0(all_survey_units,", exclude if present in less than 1/3 of years")

survey_unit_spp_list_all <- c(survey_unit_spp_list,survey_unit_spp_list_excluded_15perc, survey_unit_spp_list_excluded_onethird)

survey_unit_spp_list_all <- survey_unit_spp_list_all[order(names(survey_unit_spp_list_all))]

names(survey_unit_spp_list_all)

#save as text file
sink(here::here("output","spp_list.txt"))
print(survey_unit_spp_list_all)
sink()
```

Delete any tows without any observations
```{r}
FishGlob_clean_onethird_excluded[,tow_abundance_sum := ifelse(survey == "MEDITS", sum(num_cpue),sum(wgt_cpue)),.(haul_id)]
summary(FishGlob_clean_onethird_excluded$tow_abundance_sum)

tows_by_abundance <- unique(FishGlob_clean_onethird_excluded[,.(haul_id, tow_abundance_sum)])
tows_noabundance <- unique(FishGlob_clean_onethird_excluded[tow_abundance_sum == 0,.(haul_id, tow_abundance_sum, survey_unit, year)])

length(unique(FishGlob_clean_onethird_excluded[tow_abundance_sum == 0,haul_id])) 

FishGlob_clean_onethird_excluded <- FishGlob_clean_onethird_excluded[!(haul_id %in% tows_noabundance$haul_id)]
```

##Calculate Beta Dissimilarity between all sampling sites within every survey unit


```{r loop through all regions and years}

distances_dissimilarities_allyears_onethirdyears_excluded <- data.table("bray_curtis_dissimilarity_balanced_mean" = numeric(),
                                                 "jaccard_dissimilarity_turnover_mean" = numeric(), 
                                                 "jaccard_dissimilarity_nestedness_mean" =  numeric(), 
                                                 "bray_curtis_dissimilarity_gradient_mean" = as.numeric(), 
                                                 "jaccard_dissimilarity_total_mean" = numeric(), 
                                                 "bray_curtis_dissimilarity_total_mean" = numeric(), 
                                                 "survey" = character(), 
                                                 "survey_unit" = character(),
                                                "year" = integer(), 
                                                 "abund_biomass"  =  character())

for (i in 1:length(all_survey_units)) {
  
  FishGlob_clean_onethird_excluded_subset <- FishGlob_clean_onethird_excluded[survey_unit == all_survey_units[i], ]
  
  #map
  ####unique lat lon
  #add column with adjusted longitude for few surveys that cross dateline (NZ-CHAT and AI)
  FishGlob_clean_onethird_excluded_subset[,longitude_adj := ifelse((survey_unit %in% c("AI","NZ-CHAT") & longitude > 0),longitude-360,longitude)]

    lat_lon <- unique(FishGlob_clean_onethird_excluded_subset[, .(latitude,  longitude_adj)])

   #list years
  FishGlob_clean_onethird_excluded_subset[, year:= as.numeric(year)] #make numeric
  setorder(FishGlob_clean_onethird_excluded_subset,  year)
  years <- unique(FishGlob_clean_onethird_excluded_subset[, year])
  
  #haul id keys
  haul_ids <- unique(FishGlob_clean_onethird_excluded_subset[, haul_id])
  haul_ids_key <- data.table(haul_id = haul_ids,  key_ID = seq(1, length(haul_ids),  by = 1))
  
  
  #convert haul_ids to numeric key_ids
  FishGlob_clean_onethird_excluded_subset <- FishGlob_clean_onethird_excluded_subset[haul_ids_key,  on = "haul_id"]

          for (j in 1:length(years)) {
            reduced_year <- FishGlob_clean_onethird_excluded_subset[year == years[j], ]
            
            #distances among cells
            setorder(reduced_year,  key_ID)
            
            latitude_longitude_haul_id <- unique(reduced_year[, .(latitude, longitude, key_ID)])
            distances <- distm(latitude_longitude_haul_id[, .(longitude, latitude)])
            key_IDs <- latitude_longitude_haul_id[, key_ID]
          
            colnames(distances) <- rownames(distances) <- key_IDs
          
            #wide to long
            haul_id_distances.l <- reshape2::melt(distances, varnames = (c("haul_id1",  "haul_id2")),  value.name = "distance")
            
            #make into data table
            haul_id_distances.l <- data.table(haul_id_distances.l)
          
          if(!(reduced_year[1, survey] == "MEDITS")) {
            
            #if some rows have wgt_cpue missing,  get rid of these rows (shouldn't from previous processing)
            reduced_year <- reduced_year[complete.cases(reduced_year[, wgt_cpue]), ]
            
              reduced_year_wide <- dcast(reduced_year,  key_ID + year ~ accepted_name,  value.var = "wgt_cpue",  fun.aggregate = sum) #longitude to wide data for community matrix,  column names are cell then species
              
              
              ncols <- ncol(reduced_year_wide)
              communitymatrix <- reduced_year_wide[, 3:ncols] #community matrix
              communitymatrix.occurence <- communitymatrix
              communitymatrix.occurence[communitymatrix.occurence > 0] <- 1
            
              #list of haul_id keys
              key_IDs_subset <- reduced_year_wide[,key_ID]
            
              dissimilarities_abundance <- beta.pair.abund(communitymatrix,  index.family = "bray") #dissimilarity 
              dissimilarities_occurrence <- beta.pair(communitymatrix.occurence,  index.family = "jaccard") #dissimilarity
            
              #make into matrix
              dissimilarities_abundance_balanced.m <- as.matrix(dissimilarities_abundance$beta.bray.bal,  labels=TRUE) #bal = balanced
              dissimilarities_abundance_gradient.m <- as.matrix(dissimilarities_abundance$beta.bray.gra,  labels=TRUE) #gra = gradient
              dissimilarities_abundance_total.m <- as.matrix(dissimilarities_abundance$beta.bray,  labels=TRUE) #total
              
              dissimilarities_occurrence_turnover.m <- as.matrix(dissimilarities_occurrence$beta.jtu,  labels=TRUE) #jtu = turnover
              dissimilarities_occurrence_nestedness.m <- as.matrix(dissimilarities_occurrence$beta.jne,  labels=TRUE) #jne = nestedness
              dissimilarities_occurrence_total.m <- as.matrix(dissimilarities_occurrence$beta.jac,  labels=TRUE) #total
              
              colnames(dissimilarities_abundance_balanced.m) <- rownames(dissimilarities_abundance_balanced.m) <- key_IDs_subset
              colnames(dissimilarities_abundance_gradient.m) <- rownames(dissimilarities_abundance_gradient.m) <- key_IDs_subset
              colnames(dissimilarities_abundance_total.m) <- rownames(dissimilarities_abundance_total.m) <- key_IDs_subset
              colnames(dissimilarities_occurrence_turnover.m) <- rownames(dissimilarities_occurrence_turnover.m) <- key_IDs_subset
              colnames(dissimilarities_occurrence_nestedness.m) <- rownames(dissimilarities_occurrence_nestedness.m) <- key_IDs_subset
              colnames(dissimilarities_occurrence_total.m) <- rownames(dissimilarities_occurrence_total.m) <- key_IDs_subset
            
              #reshape dissimilarities
              dissimilarities_abundance_balanced.l <- reshape2::melt(dissimilarities_abundance_balanced.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "bray_curtis_dissimilarity_balanced")
              dissimilarities_abundance_gradient.l <- reshape2::melt(dissimilarities_abundance_gradient.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "bray_curtis_dissimilarity_gradient")
              dissimilarities_abundance_total.l <- reshape2::melt(dissimilarities_abundance_total.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "bray_curtis_dissimilarity_total")
              
              dissimilarities_occurrence_turnover.l <- reshape2::melt(dissimilarities_occurrence_turnover.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "jaccard_dissimilarity_turnover")
              dissimilarities_occurrence_nestedness.l <- reshape2::melt(dissimilarities_occurrence_nestedness.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "jaccard_dissimilarity_nestedness")
              dissimilarities_occurrence_total.l <- reshape2::melt(dissimilarities_occurrence_total.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "jaccard_dissimilarity_total")
              
              #and then to data table format
              dissimilarities_abundance_balanced.l <- data.table(dissimilarities_abundance_balanced.l)
              dissimilarities_abundance_gradient.l <- data.table(dissimilarities_abundance_gradient.l)
              dissimilarities_abundance_total.l <- data.table(dissimilarities_abundance_total.l)
              dissimilarities_occurrence_turnover.l <- data.table(dissimilarities_occurrence_turnover.l)
              dissimilarities_occurrence_nestedness.l <- data.table(dissimilarities_occurrence_nestedness.l)
              dissimilarities_occurrence_total.l <- data.table(dissimilarities_occurrence_total.l)
            
              #merge distance with dissimilarity for this year with both metrics of dissimilarity
              dissimilarities_full <- haul_id_distances.l[dissimilarities_abundance_balanced.l,  on = c("haul_id1",  "haul_id2")]
              dissimilarities_full <- dissimilarities_full[dissimilarities_occurrence_turnover.l,  on = c("haul_id1",  "haul_id2")]
              
              dissimilarities_full <- dissimilarities_full[dissimilarities_occurrence_total.l,  on = c("haul_id1",  "haul_id2")]
              
              dissimilarities_full <- dissimilarities_full[dissimilarities_occurrence_nestedness.l,  on = c("haul_id1",  "haul_id2")]
              
              dissimilarities_full <- dissimilarities_full[dissimilarities_abundance_gradient.l,  on = c("haul_id1",  "haul_id2")]
              
              dissimilarities_full <- dissimilarities_full[dissimilarities_abundance_total.l,  on = c("haul_id1",  "haul_id2")]
            
              
              #delete if haul_id2 < haul_id1 (deletes comparisons between same site (0 inflated) and any duplicate comparisons)
              dissimilarities_full <- dissimilarities_full[haul_id2 < haul_id1]
            
              #take averages
              #yearly means, deleted a few rogue NAs for balanced changes and abundance gradients
                dissimilarities_full[, bray_curtis_dissimilarity_balanced_mean := mean(bray_curtis_dissimilarity_balanced)][, bray_curtis_dissimilarity_gradient_mean := mean(bray_curtis_dissimilarity_gradient)][, bray_curtis_dissimilarity_total_mean := mean(bray_curtis_dissimilarity_total)][, jaccard_dissimilarity_turnover_mean := mean(jaccard_dissimilarity_turnover)][, jaccard_dissimilarity_nestedness_mean := mean(jaccard_dissimilarity_nestedness)][, jaccard_dissimilarity_total_mean := mean(jaccard_dissimilarity_total)]

                  #unique rows
                  dissimilarities_full.r <- unique(dissimilarities_full[,.(bray_curtis_dissimilarity_balanced_mean, bray_curtis_dissimilarity_gradient_mean, bray_curtis_dissimilarity_total_mean, jaccard_dissimilarity_turnover_mean, jaccard_dissimilarity_nestedness_mean, jaccard_dissimilarity_total_mean)])

              #add survey survey unit
              dissimilarities_full.r[, "survey" := FishGlob_clean_onethird_excluded_subset[1, survey]]
              dissimilarities_full.r[, "survey_unit" := all_survey_units[i]]
              #add year for these values
              dissimilarities_full.r[,  "year" := years[j]]
              
              #what type of metric?
              dissimilarities_full.r[, "abund_biomass" := "biomass"]
              
              #remove full dataset
              rm(dissimilarities_full)
              
              #bind with full
              distances_dissimilarities_allyears_onethirdyears_excluded <- rbind(distances_dissimilarities_allyears_onethirdyears_excluded, dissimilarities_full.r)
      
              print(paste0(j, "/", length(years)))
            
          } else { #if we do using abundance instead
            
            #if some rows have num_cpue missing,  get rid of these rows
            reduced_year <- reduced_year[complete.cases(reduced_year[, num_cpue]), ]
            
              reduced_year_wide <- dcast(reduced_year,  key_ID + year ~ accepted_name,  value.var = "num_cpue",  fun.aggregate = sum) #longitude to wide data for community matrix,  column names are cell then species
              
              
              ncols <- ncol(reduced_year_wide)
              communitymatrix <- reduced_year_wide[, 3:ncols] #community matrix
              communitymatrix.occurence <- communitymatrix
              communitymatrix.occurence[communitymatrix.occurence > 0] <- 1
            
              #list of haul_id keys
              key_IDs_subset <- reduced_year_wide[,key_ID]
            
              dissimilarities_abundance <- beta.pair.abund(communitymatrix,  index.family = "bray") #dissimilarity 
              dissimilarities_occurrence <- beta.pair(communitymatrix.occurence,  index.family = "jaccard") #dissimilarity
            
              #make into matrix
              dissimilarities_abundance_balanced.m <- as.matrix(dissimilarities_abundance$beta.bray.bal,  labels=TRUE) #bal = balanced
              dissimilarities_abundance_gradient.m <- as.matrix(dissimilarities_abundance$beta.bray.gra,  labels=TRUE) #gra = gradient
              dissimilarities_abundance_total.m <- as.matrix(dissimilarities_abundance$beta.bray,  labels=TRUE) #total
              
              dissimilarities_occurrence_turnover.m <- as.matrix(dissimilarities_occurrence$beta.jtu,  labels=TRUE) #jtu = turnover
              dissimilarities_occurrence_nestedness.m <- as.matrix(dissimilarities_occurrence$beta.jne,  labels=TRUE) #jne = nestedness
              dissimilarities_occurrence_total.m <- as.matrix(dissimilarities_occurrence$beta.jac,  labels=TRUE) #total
              
              colnames(dissimilarities_abundance_balanced.m) <- rownames(dissimilarities_abundance_balanced.m) <- key_IDs_subset
              colnames(dissimilarities_abundance_gradient.m) <- rownames(dissimilarities_abundance_gradient.m) <- key_IDs_subset
              colnames(dissimilarities_abundance_total.m) <- rownames(dissimilarities_abundance_total.m) <- key_IDs_subset
              colnames(dissimilarities_occurrence_turnover.m) <- rownames(dissimilarities_occurrence_turnover.m) <- key_IDs_subset
              colnames(dissimilarities_occurrence_nestedness.m) <- rownames(dissimilarities_occurrence_nestedness.m) <- key_IDs_subset
              colnames(dissimilarities_occurrence_total.m) <- rownames(dissimilarities_occurrence_total.m) <- key_IDs_subset
            
              #reshape dissimilarities
              dissimilarities_abundance_balanced.l <- reshape2::melt(dissimilarities_abundance_balanced.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "bray_curtis_dissimilarity_balanced")
              dissimilarities_abundance_gradient.l <- reshape2::melt(dissimilarities_abundance_gradient.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "bray_curtis_dissimilarity_gradient")
              dissimilarities_abundance_total.l <- reshape2::melt(dissimilarities_abundance_total.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "bray_curtis_dissimilarity_total")
              
              dissimilarities_occurrence_turnover.l <- reshape2::melt(dissimilarities_occurrence_turnover.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "jaccard_dissimilarity_turnover")
              dissimilarities_occurrence_nestedness.l <- reshape2::melt(dissimilarities_occurrence_nestedness.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "jaccard_dissimilarity_nestedness")
              dissimilarities_occurrence_total.l <- reshape2::melt(dissimilarities_occurrence_total.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "jaccard_dissimilarity_total")
              
              #and then to data table format
              dissimilarities_abundance_balanced.l <- data.table(dissimilarities_abundance_balanced.l)
              dissimilarities_abundance_gradient.l <- data.table(dissimilarities_abundance_gradient.l)
              dissimilarities_abundance_total.l <- data.table(dissimilarities_abundance_total.l)
              dissimilarities_occurrence_turnover.l <- data.table(dissimilarities_occurrence_turnover.l)
              dissimilarities_occurrence_nestedness.l <- data.table(dissimilarities_occurrence_nestedness.l)
              dissimilarities_occurrence_total.l <- data.table(dissimilarities_occurrence_total.l)
            
            
              #merge distance with dissimilarity for this year with both metrics of dissimilarity
              dissimilarities_full <- haul_id_distances.l[dissimilarities_abundance_balanced.l,  on = c("haul_id1",  "haul_id2")]
              dissimilarities_full <- dissimilarities_full[dissimilarities_occurrence_turnover.l,  on = c("haul_id1",  "haul_id2")]
              
              dissimilarities_full <- dissimilarities_full[dissimilarities_occurrence_total.l,  on = c("haul_id1",  "haul_id2")]
              
              dissimilarities_full <- dissimilarities_full[dissimilarities_occurrence_nestedness.l,  on = c("haul_id1",  "haul_id2")]
              
              dissimilarities_full <- dissimilarities_full[dissimilarities_abundance_gradient.l,  on = c("haul_id1",  "haul_id2")]
              
              dissimilarities_full <- dissimilarities_full[dissimilarities_abundance_total.l,  on = c("haul_id1",  "haul_id2")]
              
              
              #delete if haul_id2 < haul_id1 (deletes comparisons between same site (0 inflated) and any duplicate comparisons)
              dissimilarities_full <- dissimilarities_full[haul_id2<haul_id1]
            
              #take averages
              #yearly means, deleted a few rogue NAs for balanced changes and abundance gradients
                dissimilarities_full[, bray_curtis_dissimilarity_balanced_mean := mean(bray_curtis_dissimilarity_balanced)][, bray_curtis_dissimilarity_gradient_mean := mean(bray_curtis_dissimilarity_gradient)][, bray_curtis_dissimilarity_total_mean := mean(bray_curtis_dissimilarity_total)][, jaccard_dissimilarity_turnover_mean := mean(jaccard_dissimilarity_turnover)][, jaccard_dissimilarity_nestedness_mean := mean(jaccard_dissimilarity_nestedness)][, jaccard_dissimilarity_total_mean := mean(jaccard_dissimilarity_total)]

                  #unique rows
                  dissimilarities_full.r <- unique(dissimilarities_full[,.(bray_curtis_dissimilarity_balanced_mean, bray_curtis_dissimilarity_gradient_mean, bray_curtis_dissimilarity_total_mean, jaccard_dissimilarity_turnover_mean, jaccard_dissimilarity_nestedness_mean, jaccard_dissimilarity_total_mean)])

              #add survey survey unit
              dissimilarities_full.r[, "survey" := FishGlob_clean_onethird_excluded_subset[1, survey]]
              dissimilarities_full.r[, "survey_unit" := all_survey_units[i]]
              #add year for these values
              dissimilarities_full.r[,  "year" := years[j]]
              
              #what type of metric?
              dissimilarities_full.r[, "abund_biomass" := "abund"]
              
              #remove full dataset
              rm(dissimilarities_full)
              
              #bind with full
              distances_dissimilarities_allyears_onethirdyears_excluded <- rbind(distances_dissimilarities_allyears_onethirdyears_excluded, dissimilarities_full.r)
              
              print(paste0(j, "/", length(years)))
          
              } #closes if else abundance versus biomass

  
         } #closes year
  
  print(paste0("We have cycled through ",  i, " of ", length(all_survey_units),  " total survey/season combos"))
  
  } #closes survey/region

#Be sure to check which one of these you actually want to un-hash!

saveRDS(distances_dissimilarities_allyears_onethirdyears_excluded,  here::here("output","dissimilarities", "distances_dissimilarities_allyears_onethirdyears_excluded.rds"))

distances_dissimilarities_allyears_onethirdyears_excluded <- readRDS(here::here("output","dissimilarities", "distances_dissimilarities_allyears_onethirdyears_excluded.rds"))
```
 




