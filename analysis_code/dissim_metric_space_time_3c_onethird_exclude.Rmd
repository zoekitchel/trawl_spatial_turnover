---
title: "Calculating Dissimilarity Metrics Across Space and Time for species present at least 1/3 of timeseries for each survey"
output: html_notebook
author: ZoÃ« J. Kitchel
date: May 9, 2024
---

Script 3c for Kitchel et al. 2024 in prep taxonomic diversity manuscript.

```{r setup}
library(data.table)
library(vegan)
library(sf)
library(concaveman) #polygon around points
library(betapart) #allows us to partition beta diversity
library(geosphere)
library(ggpubr) #stat_regline_equation
library(nlme)


FishGlob_clean.singleseason <- readRDS(here::here("data", "cleaned", "FishGlob_clean.singleseason.rds"))


```

Loop through all regions (takes  a few hours to run)

```{r list of all survey season combinations}
all_survey_units <- unique(FishGlob_clean.singleseason[, survey_unit])
```

Delete any species that are not present in at least 1/3 of years in time series.
```{r}
#only keep rows where either wgt or num are over 0
FishGlob_clean.singleseason <- FishGlob_clean.singleseason[wgt_cpue >0 | num_cpue > 0,]

#unique year, survey, species combinations to identify total # of years for each survey, and total # of years a given species appears
unique_year_survey_spp <- unique(FishGlob_clean.singleseason[,.(accepted_name, year, survey_unit)])

#calculate the total number of years sampled per survey
#calculate the number of years a particular species appeared in the survey
unique_year_survey_spp[,years_sampled_survey := uniqueN(year),survey_unit][,years_spp_occurs := .N,.(accepted_name, survey_unit)][,perc_occurence := round(years_spp_occurs/years_sampled_survey,2)][,keep := ifelse(perc_occurence>=(1/3),T,F)] #keep = TRUE if above 0.33 presence, FALSE if below 0.33 presence

keep_drop_key <- unique(unique_year_survey_spp[,.(accepted_name, survey_unit,keep)])

FishGlob_clean.singleseason_onethird <- keep_drop_key[FishGlob_clean.singleseason, on = .(survey_unit, accepted_name)]

FishGlob_clean.singleseason_twothirdsthird_included <- FishGlob_clean.singleseason_onethird[keep == T,]

FishGlob_clean.singleseason_onethirdyears_excluded <- FishGlob_clean.singleseason_onethird[keep == F,]

#drops 
nrow(FishGlob_clean.singleseason_onethirdyears_excluded)
#11861/2220730 rows (0.5% of observations)

length(unique(FishGlob_clean.singleseason_onethirdyears_excluded$accepted_name)) #number of species kept
```


###Dataset statistics

Delete any tows without any observations
Add new column presence = 1 where if either abundance or biomass >1, presence = YES
```{r}
#Calculate total number of critters and total biomass of critters in each tow. In this case, it's okay if sum(NA,NA,NA) --> 0, because we will still delete hauls with all 0s

FishGlob_clean.singleseason_onethirdyears_excluded[,tow_abundance_sum := sum(num_cpue, na.rm = T),.(haul_id)]
FishGlob_clean.singleseason_onethirdyears_excluded[,tow_biomass_sum := sum(wgt_cpue, na.rm = T),.(haul_id)]
hist(FishGlob_clean.singleseason_onethirdyears_excluded$num_cpue)
hist(FishGlob_clean.singleseason_onethirdyears_excluded$wgt_cpue)

summary(FishGlob_clean.singleseason_onethirdyears_excluded$tow_abundance_sum)
summary(FishGlob_clean.singleseason_onethirdyears_excluded$tow_biomass_sum)

tows_by_abundance <- unique(FishGlob_clean.singleseason_onethirdyears_excluded[,.(haul_id, tow_abundance_sum)])
tows_by_biomass <- unique(FishGlob_clean.singleseason_onethirdyears_excluded[,.(haul_id, tow_biomass_sum)])
tows_noabundancebiomass <- unique(FishGlob_clean.singleseason_onethirdyears_excluded[!(tow_abundance_sum > 0 | tow_biomass_sum > 0),.(haul_id, tow_abundance_sum,tow_biomass_sum, survey_unit, year)]) #there are no rows where BOTH abundance and biomass are 0 or NA

#New presence absence column
FishGlob_clean.singleseason_onethirdyears_excluded[,Present := ifelse(num_cpue>0|wgt_cpue>0,1,0)]

#Delete absenses (which are NA's) 
FishGlob_clean.singleseason_onethirdyears_excluded <- FishGlob_clean.singleseason_onethirdyears_excluded[!is.na(Present),] 

#From  above, this new column should be 100% 1
summary(FishGlob_clean.singleseason_onethirdyears_excluded$Present) #check yes

length(unique(FishGlob_clean.singleseason_onethirdyears_excluded[tow_abundance_sum <= 0,haul_id])) #13123 tows out of 178531 have no abundance observations (o for all), 7%
length(unique(FishGlob_clean.singleseason_onethirdyears_excluded[tow_biomass_sum <= 0,haul_id])) #25074 tows out of 178531 have no abundance observations (o for all), 14%
#KEEP IN MIND ALL BIOMASS OBSERVATIONS FOR EUROPE SHOULD BE DELETED ANYWAY BECAUSE THEY WERE CALCULATED USING LENGTH WEIGHT RELATIONSHIPS AND WERE NOT MEASURED CONSISTENTLY ON BOARD

#clean up
rm(tows_by_abundance, tows_by_biomass)

```

Total observations? (spp x tows)
```{r}
nrow(FishGlob_clean.singleseason_onethirdyears_excluded)
```

Total tows?
```{r}
length(unique(FishGlob_clean.singleseason_onethirdyears_excluded[,haul_id]))
```

Total survey units?
```{r}
length(unique(FishGlob_clean.singleseason_onethirdyears_excluded[,survey_unit]))
```

Total species?
```{r}
length(unique(FishGlob_clean.singleseason_onethirdyears_excluded[,accepted_name]))
```

##Calculate Beta Dissimilarity between all sampling sites within every survey unit

Calculate dissimilarity using jaccard, and bray curtis for both abundance and biomass
```{r loop through all regions and years}

distances_dissimilarities_allyears_onethirdyears_excluded <- data.table("survey" = character(), 
                                                 "survey_unit" = character(),
                                                "year" = integer(),
                                                "dissimilarity_metric" = character(),
                                                "annual_dissimilarity_value" = numeric())

for (i in 1:length(all_survey_units)) {
  
  FishGlob_clean.singleseason_onethirdyears_excluded_subset <- FishGlob_clean.singleseason_onethirdyears_excluded[survey_unit == all_survey_units[i], ]
  
  distances_dissimilarities_onereg <- data.table("survey" = character(), 
                                                 "survey_unit" = character(),
                                                "year" = integer(),
                                                "dissimilarity_metric" = character(),
                                                "annual_dissimilarity_value" = numeric())
  
  #map
  ####unique lat lon
  #add column with adjusted longitude for few surveys that cross dateline (NZ-CHAT and AI)
  FishGlob_clean.singleseason_onethirdyears_excluded_subset[,longitude_adj := ifelse((survey_unit %in% c("AI","NZ-CHAT") & longitude > 0),longitude-360,longitude)]

    lat_lon <- unique(FishGlob_clean.singleseason_onethirdyears_excluded_subset[, .(latitude,  longitude_adj)])

   #list years
  FishGlob_clean.singleseason_onethirdyears_excluded_subset[, year:= as.numeric(year)] #make numeric
  setorder(FishGlob_clean.singleseason_onethirdyears_excluded_subset,  year)
  years <- unique(FishGlob_clean.singleseason_onethirdyears_excluded_subset[, year])
  
  #haul id keys
  haul_ids <- unique(FishGlob_clean.singleseason_onethirdyears_excluded_subset[, haul_id])
  haul_ids_key <- data.table(haul_id = haul_ids,  key_ID = seq(1, length(haul_ids),  by = 1))
  
  
  #convert haul_ids to numeric key_ids
  FishGlob_clean.singleseason_onethirdyears_excluded_subset <- FishGlob_clean.singleseason_onethirdyears_excluded_subset[haul_ids_key,  on = "haul_id"]

          for (j in 1:length(years)) {
            reduced_year <- FishGlob_clean.singleseason_onethirdyears_excluded_subset[year == years[j], ]
            
            #make sure that haul_id, survey_unit, latitude, longitude, key_id, wgt_cpue, num_cpue, year, month, accepted name and day are unique (this is an issue with Namibia, where there is somehow repetition for just 5 observations of one species (Yarrella blackfordi, fixed by this step))
            reduced_year.u <- unique(reduced_year[,.(haul_id, survey_unit, latitude, longitude, key_ID, wgt_cpue, num_cpue, Present, year, month, day, accepted_name)])
            
            #distances among cells
            setorder(reduced_year.u,  key_ID)
            
            latitude_longitude_haul_id <- unique(reduced_year.u[, .(latitude, longitude, key_ID)])
            distances <- distm(latitude_longitude_haul_id[, .(longitude, latitude)])
            key_IDs <- latitude_longitude_haul_id[, key_ID]
          
            colnames(distances) <- rownames(distances) <- key_IDs
          
            #wide to long
            haul_id_distances.l <- reshape2::melt(distances, varnames = (c("haul_id1",  "haul_id2")),  value.name = "distance")
            
            #make into data table
            haul_id_distances.l <- data.table(haul_id_distances.l)
########################################################################
########################################################################
  #First, calculate Jaccard dissimilarity metrics (this metric can be calculated for all regions)
               
             #Only include rows where presence = 1
            reduced_year_occurence <- copy(reduced_year.u[Present == 1, ])
            
              reduced_year_wide <- dcast(reduced_year_occurence,  key_ID + year ~ accepted_name,  value.var = "Present",  fun.aggregate = sum) #longitude to wide data for community matrix,  column names are cell then species
              
              
              ncols <- ncol(reduced_year_wide)
              communitymatrix.occurence <- reduced_year_wide[, 3:ncols] #community matrix
            
              #list of haul_id keys
              key_IDs_subset <- reduced_year_wide[,key_ID]

              #calculate Jaccard pair-wise dissimilarity
              dissimilarities_occurrence <- beta.pair(communitymatrix.occurence,  index.family = "jaccard") #dissimilarity
            
              #make into matrix

              dissimilarities_occurrence_total.m <- as.matrix(dissimilarities_occurrence$beta.jac,  labels=TRUE) #total
              #make column names link to key IDs 

              colnames(dissimilarities_occurrence_total.m) <- rownames(dissimilarities_occurrence_total.m) <- key_IDs_subset
            
              #reshape dissimilarities from wide to long

              dissimilarities_occurrence_total.l <- reshape2::melt(dissimilarities_occurrence_total.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "jaccard_dissimilarity_total")
              
              #and then to data table format

              dissimilarities_occurrence_all <- data.table(dissimilarities_occurrence_total.l)
              
                            
              #again, wide to long
               dissimilarities_occurrence_all.l <- reshape2::melt(dissimilarities_occurrence_all,
              id.vars = c("haul_id1",  "haul_id2"), variable.name = "dissimilarity_metric", value.name = "value")
            
              #merge distance with dissimilarity for this year with both metrics of dissimilarity
              dissimilarities_full <- haul_id_distances.l[dissimilarities_occurrence_all.l,  on = c("haul_id1",  "haul_id2")]
              
              
              #delete if haul_id2 < haul_id1 (deletes comparisons between same site (0 inflated) and any duplicate comparisons)
              dissimilarities_full <- dissimilarities_full[haul_id2 < haul_id1]
            
              #take averages
              #yearly means, deleted a few rogue NAs for balanced changes and abundance gradients
                dissimilarities_full[,annual_dissimilarity_value := mean(value),.(dissimilarity_metric)]

                  #unique rows
                  dissimilarities_full.r <- unique(dissimilarities_full[,.(dissimilarity_metric, annual_dissimilarity_value)])

              #add survey survey unit
              dissimilarities_full.r[, "survey" := FishGlob_clean.singleseason_onethirdyears_excluded_subset[1, survey]]
              dissimilarities_full.r[, "survey_unit" := all_survey_units[i]]
              #add year for these values
              dissimilarities_full.r[,  "year" := years[j]]
              
              #reorder
              dissimilarities_full.r <-  dissimilarities_full.r[,.(survey, survey_unit, year, dissimilarity_metric, annual_dissimilarity_value)]
   
              #remove full dataset
              rm(dissimilarities_full)
              
              #bind with full for this reg
              distances_dissimilarities_onereg <- rbind(distances_dissimilarities_onereg, dissimilarities_full.r)
    
              print(paste0(j, "/", length(years))) #print year that we're on

  
         } #closes year
  
  #save the output from this region
  filename <- paste0(all_survey_units[i],"_dissimilarity.rds")
  saveRDS(distances_dissimilarities_onereg, here::here("output","dissimilarities","by_region_onethirdyears_excluded",filename))
  rm(distances_dissimilarities_onereg) #attempt to save some memory here
  
  print(paste0("We have cycled through ",  i, " of ", length(all_survey_units),  " surveys"))
  
  } #closes survey/region

#merge all years into distances_dissimilarities_allyears_onethirdyears_excluded
files <- list.files(here::here("output","dissimilarities","by_region_onethirdyears_excluded"))

for(i in 1:length(files)){
  regional_dissimilarity <- readRDS(here::here("output","dissimilarities","by_region_onethirdyears_excluded",files[i]))
  distances_dissimilarities_allyears_onethirdyears_excluded <- rbind(distances_dissimilarities_allyears_onethirdyears_excluded, regional_dissimilarity)
}


#Be sure to check which one of these you actually want to un-hash!

saveRDS(distances_dissimilarities_allyears_onethirdyears_excluded,  here::here("output","dissimilarities", "distances_dissimilarities_allyears_onethirdyears_excluded.rds"))

#distances_dissimilarities_allyears_onethirdyears_excluded <- readRDS(here::here("output","dissimilarities", "distances_dissimilarities_allyears_onethirdyears_excluded.rds"))
```
 



