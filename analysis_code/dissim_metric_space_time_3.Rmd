---
title: "Calculating Dissimilarity Metrics Across Space and Time"
author: ZoÃ« J. Kitchel
date: May 4, 2024
output: html_notebook
---
Script 3 for Kitchel et al. 2024 in prep taxonomic diversity manuscript.

###UPDATE
May 4 Transitioned to single season only for each region
May 4 Added another analysis for regions with ONLY abundance or ONLY biomass

```{r setup}
library(data.table)
library(vegan)
library(sf)
library(concaveman) #polygon around points
library(betapart) #allows us to calculate beta diversity with multiple metrics
library(geosphere)
library(ggpubr) #stat_regline_equation
library(nlme)
```

Pull in clean fishglob data
```{r pull in clean fishglob data}
FishGlob_clean.singleseason <- readRDS(here::here("data", "cleaned", "FishGlob_clean.singleseason.rds"))


```

Loop through all regions (takes 6+ hours to run)

```{r list of all survey season combinations}
all_survey_units <- sort(unique(FishGlob_clean.singleseason[, survey_unit]))
```

###Dataset statistics

Delete any tows without any observations
Add new column presence = 1 where if either abundance or biomass >1, presence = YES
```{r}
#Calculate total number of critters and total biomass of critters in each tow. In this case, it's okay if sum(NA,NA,NA) --> 0, because we will still delete hauls with all 0s

FishGlob_clean.singleseason[,tow_abundance_sum := sum(num_cpue, na.rm = T),.(haul_id)]
FishGlob_clean.singleseason[,tow_biomass_sum := sum(wgt_cpue, na.rm = T),.(haul_id)]
hist(FishGlob_clean.singleseason$num_cpue)
hist(FishGlob_clean.singleseason$wgt_cpue)

summary(FishGlob_clean.singleseason$tow_abundance_sum)
summary(FishGlob_clean.singleseason$tow_biomass_sum)

tows_by_abundance <- unique(FishGlob_clean.singleseason[,.(haul_id, tow_abundance_sum)])
tows_by_biomass <- unique(FishGlob_clean.singleseason[,.(haul_id, tow_biomass_sum)])
tows_noabundancebiomass <- unique(FishGlob_clean.singleseason[!(tow_abundance_sum > 0 | tow_biomass_sum > 0),.(haul_id, tow_abundance_sum,tow_biomass_sum, survey_unit, year)]) #there are no rows where BOTH abundance and biomass are 0 or NA

#New presence absence column
FishGlob_clean.singleseason[,Present := ifelse(num_cpue>0|wgt_cpue>0,1,0)]

#Delete absenses (which are NA's) Drops from 2224344 to 2219440, 
FishGlob_clean.singleseason <- FishGlob_clean.singleseason[!is.na(Present),] 

#From  above, this new column should be 100% 1
summary(FishGlob_clean.singleseason$Present) #check yes

length(unique(FishGlob_clean.singleseason[tow_abundance_sum <= 0,haul_id])) #13131 tows out of 178531 have no abundance observations (o for all), 7%
length(unique(FishGlob_clean.singleseason[tow_biomass_sum <= 0,haul_id])) #25074 tows out of 178531 have no abundance observations (o for all), 14%
#KEEP IN MIND ALL BIOMASS OBSERVATIONS FOR EUROPE SHOULD BE DELETED ANYWAY BECAUSE THEY WERE CALCULATED USING LENGTH WEIGHT RELATIONSHIPS AND WERE NOT MEASURED CONSISTENTLY ON BOARD

#clean up
rm(tows_by_abundance, tows_by_biomass)

```

Total observations? (spp x tows)
```{r}
nrow(FishGlob_clean.singleseason)
```

Total tows?
```{r}
length(unique(FishGlob_clean.singleseason[,haul_id]))
```

Total survey units?
```{r}
length(unique(FishGlob_clean.singleseason[,survey_unit]))
```

Total species?
```{r}
length(unique(FishGlob_clean.singleseason[,accepted_name]))
```


Survey Statistics for all regions in a table
```{r}
#Calculate survey details only

survey_stats <- data.table(survey = character() ,  
                           survey_unit = character(),  spp_num = numeric(),  
                           study_period = numeric(),  study_duration = numeric(),  
                           lat_range = numeric(),  mid_lat = numeric(),  lon_range = numeric(),  
                           area = numeric(),  depth_range = numeric(),   mid_depth = numeric())


for (i in 1:length(all_survey_units)) {
  
  FishGlob_clean.singleseason_subset <- FishGlob_clean.singleseason[survey_unit == all_survey_units[i], ]
  
  #map
  ####unique lat lon
  #add column with adjusted longitude for few surveys that cross dateline (NZ-CHAT and AI)
  FishGlob_clean.singleseason_subset[,longitude_adj := ifelse((survey_unit %in% c("AI","NZ-CHAT") & longitude > 0),longitude-360,longitude)]
  
  lat_lon <- unique(FishGlob_clean.singleseason_subset[, .(latitude,  longitude_adj)])
  
  pts <- st_as_sf(lat_lon,  coords=c('longitude_adj', 'latitude'),  crs=4326 )
  
  conc <- concaveman(pts,  concavity = 5)
  sf::sf_use_s2(FALSE) #turn off the s2 processing; GEOS treats projected coordinates as planar (i.e. two points lie on a line of infinite max lenght) while s2 is more "correct" (two points lie on a great circle of circumference of 40 075 kilometers)
  area <- st_area(conc) #m2,  check this later
  
  #fill row
  row <- data.table(FishGlob_clean.singleseason_subset[1, survey], 
                    FishGlob_clean.singleseason_subset[1, as.character(survey_unit)], 
                    as.numeric(length(unique(FishGlob_clean.singleseason_subset[, accepted_name]))), 
                    as.numeric(max(FishGlob_clean.singleseason_subset[, year])-min(FishGlob_clean.singleseason_subset[, year])), 
                    as.numeric(length(unique(FishGlob_clean.singleseason_subset[, year]))), 
                    as.numeric(max(FishGlob_clean.singleseason_subset[, latitude])-min(FishGlob_clean.singleseason_subset[, latitude])), 
                    as.numeric(mean(FishGlob_clean.singleseason_subset[, latitude])), 
                    as.numeric(max(FishGlob_clean.singleseason_subset[, longitude_adj])-min(FishGlob_clean.singleseason_subset[, longitude_adj])), 
                    as.numeric(area), 
                    as.numeric(max(FishGlob_clean.singleseason_subset[, as.numeric(depth)],  na.rm = T)-min(FishGlob_clean.singleseason_subset[, as.numeric(depth)],  na.rm = T)), 
                    as.numeric(mean(FishGlob_clean.singleseason_subset[, as.numeric(depth)],  na.rm = T)))
  
  survey_stats <- rbind(survey_stats,  row,  use.names = F)
  
  
}
```


###Biomass and Abundance subsets
```{r}
abun_subset <- c(
"BITS-1",
"EVHOE",
"FR-CGFS",
"IE-IGFS",
"MEDITS",
"NIGFS-1",
"NS-IBTS-3",
"PT-IBTS",
"ROCKALL",
"SWC-IBTS-1",
"AI",
"DFO-NF",
"EBS",
"GMEX-Fall",
"GOA",
"GRL-DE",
"GSL-N",
"GSL-S",
"ICE-GFS",
"NEUS-Fall",
"Nor-BTS-3",
"SCS-SUMMER",
"SEUS-fall",
"WCANN"
)

bio_subset <- c(
"CHL",
"DFO-QCS",
"NAM",
"NZ-CHAT",
"NZ-ECSI",
"NZ-SUBA",
"NZ-WCSI",
"S-GEORG",
"ZAF-ATL",
"ZAF-IND",
"AI",
"DFO-NF",
"EBS",
"GMEX-Fall",
"GOA",
"GRL-DE",
"GSL-N",
"GSL-S",
"ICE-GFS",
"NEUS-Fall",
"Nor-BTS-3",
"SCS-SUMMER",
"SEUS-fall",
"WCANN"
)

```

##Calculate Beta Dissimilarity between all sampling sites within every survey unit

Calculate dissimilarity using jaccard, and bray curtis for both abundance and biomass
```{r loop through all regions and years}

distances_dissimilarities_allyears <- data.table("survey" = character(), 
                                                 "survey_unit" = character(),
                                                "year" = integer(),
                                                "dissimilarity_metric" = character(),
                                                "annual_dissimilarity_value" = numeric())

#variables: 
#  "bray_curtis_dissimilarity_balanced_mean" = numeric(),
#                                                 "jaccard_dissimilarity_turnover_mean" = numeric(), 
#                                                 "jaccard_dissimilarity_nestedness_mean" =  numeric(), 
#                                                 "bray_curtis_dissimilarity_gradient_mean" = as.numeric(), 
#                                                 "jaccard_dissimilarity_total_mean" = numeric(), 
#                                                 "bray_curtis_dissimilarity_total_mean_biomass" = numeric(), 
#                                                   "bray_curtis_dissimilarity_total_mean_abundance" = numeric(), 
#

for (i in 1:length(all_survey_units)) {
  
  FishGlob_clean.singleseason_subset <- FishGlob_clean.singleseason[survey_unit == all_survey_units[i], ]
  
  distances_dissimilarities_onereg <- data.table("survey" = character(), 
                                                 "survey_unit" = character(),
                                                "year" = integer(),
                                                "dissimilarity_metric" = character(),
                                                "annual_dissimilarity_value" = numeric())
  
  #map
  ####unique lat lon
  #add column with adjusted longitude for few surveys that cross dateline (NZ-CHAT and AI)
  FishGlob_clean.singleseason_subset[,longitude_adj := ifelse((survey_unit %in% c("AI","NZ-CHAT") & longitude > 0),longitude-360,longitude)]

    lat_lon <- unique(FishGlob_clean.singleseason_subset[, .(latitude,  longitude_adj)])

   #list years
  FishGlob_clean.singleseason_subset[, year:= as.numeric(year)] #make numeric
  setorder(FishGlob_clean.singleseason_subset,  year)
  years <- unique(FishGlob_clean.singleseason_subset[, year])
  
  #haul id keys
  haul_ids <- unique(FishGlob_clean.singleseason_subset[, haul_id])
  haul_ids_key <- data.table(haul_id = haul_ids,  key_ID = seq(1, length(haul_ids),  by = 1))
  
  
  #convert haul_ids to numeric key_ids
  FishGlob_clean.singleseason_subset <- FishGlob_clean.singleseason_subset[haul_ids_key,  on = "haul_id"]

          for (j in 1:length(years)) {
            reduced_year <- FishGlob_clean.singleseason_subset[year == years[j], ]
            
            #make sure that haul_id, survey_unit, latitude, longitude, key_id, wgt_cpue, num_cpue, year, month, accepted name and day are unique (this is an issue with Namibia, where there is somehow repetition for just 5 observations of one species (Yarrella blackfordi, fixed by this step))
            reduced_year.u <- unique(reduced_year[,.(haul_id, survey_unit, latitude, longitude, key_ID, wgt_cpue, num_cpue, Present, year, month, day, accepted_name)])
            
            #distances among cells
            setorder(reduced_year.u,  key_ID)
            
            latitude_longitude_haul_id <- unique(reduced_year.u[, .(latitude, longitude, key_ID)])
            distances <- distm(latitude_longitude_haul_id[, .(longitude, latitude)])
            key_IDs <- latitude_longitude_haul_id[, key_ID]
          
            colnames(distances) <- rownames(distances) <- key_IDs
          
            #wide to long
            haul_id_distances.l <- reshape2::melt(distances, varnames = (c("haul_id1",  "haul_id2")),  value.name = "distance")
            
            #make into data table
            haul_id_distances.l <- data.table(haul_id_distances.l)
########################################################################
########################################################################
  #First, calculate Jaccard dissimilarity metrics (this metric can be calculated for all regions)
               
             #Only include rows where presence = 1
            reduced_year_occurence <- copy(reduced_year.u[Present == 1, ])
            
              reduced_year_wide <- dcast(reduced_year_occurence,  key_ID + year ~ accepted_name,  value.var = "Present",  fun.aggregate = sum) #longitude to wide data for community matrix,  column names are cell then species
              
              
              ncols <- ncol(reduced_year_wide)
              communitymatrix.occurence <- reduced_year_wide[, 3:ncols] #community matrix
            
              #list of haul_id keys
              key_IDs_subset <- reduced_year_wide[,key_ID]

              #calculate Jaccard pair-wise dissimilarity
              dissimilarities_occurrence <- beta.pair(communitymatrix.occurence,  index.family = "jaccard") #dissimilarity
            
              #make into matrix
              dissimilarities_occurrence_turnover.m <- as.matrix(dissimilarities_occurrence$beta.jtu,  labels=TRUE) #jtu = turnover
              dissimilarities_occurrence_nestedness.m <- as.matrix(dissimilarities_occurrence$beta.jne,  labels=TRUE) #jne = nestedness
              dissimilarities_occurrence_total.m <- as.matrix(dissimilarities_occurrence$beta.jac,  labels=TRUE) #total
              #make column names link to key IDs 
              colnames(dissimilarities_occurrence_turnover.m) <- rownames(dissimilarities_occurrence_turnover.m) <- key_IDs_subset
              colnames(dissimilarities_occurrence_nestedness.m) <- rownames(dissimilarities_occurrence_nestedness.m) <- key_IDs_subset
              colnames(dissimilarities_occurrence_total.m) <- rownames(dissimilarities_occurrence_total.m) <- key_IDs_subset
            
              #reshape dissimilarities from wide to long
              dissimilarities_occurrence_turnover.l <- reshape2::melt(dissimilarities_occurrence_turnover.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "jaccard_dissimilarity_turnover")
              dissimilarities_occurrence_nestedness.l <- reshape2::melt(dissimilarities_occurrence_nestedness.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "jaccard_dissimilarity_nestedness")
              dissimilarities_occurrence_total.l <- reshape2::melt(dissimilarities_occurrence_total.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "jaccard_dissimilarity_total")
              
              #and then to data table format
              dissimilarities_occurrence_turnover.l <- data.table(dissimilarities_occurrence_turnover.l)
              dissimilarities_occurrence_nestedness.l <- data.table(dissimilarities_occurrence_nestedness.l)
              dissimilarities_occurrence_total.l <- data.table(dissimilarities_occurrence_total.l)
              
              #merge into single data table
              dissimilarities_occurrence_all <- dissimilarities_occurrence_turnover.l[dissimilarities_occurrence_nestedness.l, on = c("haul_id1","haul_id2")]
              
               dissimilarities_occurrence_all <- dissimilarities_occurrence_all[dissimilarities_occurrence_total.l, on = c("haul_id1","haul_id2")]
                            
              #again, wide to long
               dissimilarities_occurrence_all.l <- reshape2::melt(dissimilarities_occurrence_all,
              id.vars = c("haul_id1",  "haul_id2"), variable.name = "dissimilarity_metric", value.name = "value")
            
              #merge distance with dissimilarity for this year with both metrics of dissimilarity
              dissimilarities_full <- haul_id_distances.l[dissimilarities_occurrence_all.l,  on = c("haul_id1",  "haul_id2")]
              
              
              #delete if haul_id2 < haul_id1 (deletes comparisons between same site (0 inflated) and any duplicate comparisons)
              dissimilarities_full <- dissimilarities_full[haul_id2 < haul_id1]
            
              #take averages
              #yearly means, deleted a few rogue NAs for balanced changes and abundance gradients
                dissimilarities_full[,annual_dissimilarity_value := mean(value),.(dissimilarity_metric)]

                  #unique rows
                  dissimilarities_full.r <- unique(dissimilarities_full[,.(dissimilarity_metric, annual_dissimilarity_value)])

              #add survey survey unit
              dissimilarities_full.r[, "survey" := FishGlob_clean.singleseason_subset[1, survey]]
              dissimilarities_full.r[, "survey_unit" := all_survey_units[i]]
              #add year for these values
              dissimilarities_full.r[,  "year" := years[j]]
              
              #reorder
              dissimilarities_full.r <-  dissimilarities_full.r[,.(survey, survey_unit, year, dissimilarity_metric, annual_dissimilarity_value)]
   
              #remove full dataset
              rm(dissimilarities_full)
              
              #bind with full for this reg
              distances_dissimilarities_onereg <- rbind(distances_dissimilarities_onereg, dissimilarities_full.r)
              
########################################################################
########################################################################
  #Second, if data are available, calculate Bray-Curtis dissimilarity metrics based on biomass 
          
          if(all_survey_units[i] %in% bio_subset) { #BIOMASS BASED BRAY CURTIS CALCULATIONS
            
            #if some rows have wgt_cpue missing,get rid of these rows
            reduced_year_bio <- copy(reduced_year.u[complete.cases(reduced_year.u[, wgt_cpue]), ])
            
              reduced_year_wide <- dcast(reduced_year_bio,  key_ID + year ~ accepted_name,  value.var = "wgt_cpue",  fun.aggregate = sum) #longitude to wide data for community matrix,  column names are cell then species
              
              
              ncols <- ncol(reduced_year_wide)
              communitymatrix <- reduced_year_wide[, 3:ncols] #community matrix

            
              #list of haul_id keys
              key_IDs_subset <- reduced_year_wide[,key_ID]
            
              #Calculate Bray Curtis dissimilarity values
              dissimilarities_abundance <- beta.pair.abund(communitymatrix,  index.family = "bray") #dissimilarity 
             
              #make into matrix
              dissimilarities_abundance_balanced.m <- as.matrix(dissimilarities_abundance$beta.bray.bal,  labels=TRUE) #bal = balanced
              dissimilarities_abundance_gradient.m <- as.matrix(dissimilarities_abundance$beta.bray.gra,  labels=TRUE) #gra = gradient
              dissimilarities_abundance_total.m <- as.matrix(dissimilarities_abundance$beta.bray,  labels=TRUE) #total
              
              colnames(dissimilarities_abundance_balanced.m) <- rownames(dissimilarities_abundance_balanced.m) <- key_IDs_subset
              colnames(dissimilarities_abundance_gradient.m) <- rownames(dissimilarities_abundance_gradient.m) <- key_IDs_subset
              colnames(dissimilarities_abundance_total.m) <- rownames(dissimilarities_abundance_total.m) <- key_IDs_subset
            
            
              #reshape dissimilarities
              dissimilarities_abundance_balanced.l <- reshape2::melt(dissimilarities_abundance_balanced.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "bray_curtis_dissimilarity_balanced_biomass")
              dissimilarities_abundance_gradient.l <- reshape2::melt(dissimilarities_abundance_gradient.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "bray_curtis_dissimilarity_gradient_biomass")
              dissimilarities_abundance_total.l <- reshape2::melt(dissimilarities_abundance_total.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "bray_curtis_dissimilarity_total_biomass")
              
              #and then to data table format
              dissimilarities_abundance_balanced.l <- data.table(dissimilarities_abundance_balanced.l)
              dissimilarities_abundance_gradient.l <- data.table(dissimilarities_abundance_gradient.l)
              dissimilarities_abundance_total.l <- data.table(dissimilarities_abundance_total.l)
            
            #merge into single data table
              dissimilarities_abundance_all <- dissimilarities_abundance_balanced.l[dissimilarities_abundance_gradient.l, on = c("haul_id1","haul_id2")]
              
               dissimilarities_abundance_all <- dissimilarities_abundance_all[dissimilarities_abundance_total.l, on = c("haul_id1","haul_id2")]
                            
              #again, wide to long
               dissimilarities_abundance_all.l <- reshape2::melt(dissimilarities_abundance_all,
              id.vars = c("haul_id1",  "haul_id2"), variable.name = "dissimilarity_metric", value.name = "value")
            
              #merge distance with dissimilarity for this year with both metrics of dissimilarity
              dissimilarities_full <- haul_id_distances.l[dissimilarities_abundance_all.l,  on = c("haul_id1",  "haul_id2")]
              
              
              #delete if haul_id2 < haul_id1 (deletes comparisons between same site (0 inflated) and any duplicate comparisons)
              dissimilarities_full <- dissimilarities_full[haul_id2 < haul_id1]
            
              #take averages
              #yearly means, deleted a few rogue NAs for balanced changes and abundance gradients
                dissimilarities_full[,annual_dissimilarity_value := mean(value),.(dissimilarity_metric)]

                  #unique rows
                  dissimilarities_full.r <- unique(dissimilarities_full[,.(dissimilarity_metric, annual_dissimilarity_value)])

              #add survey survey unit
              dissimilarities_full.r[, "survey" := FishGlob_clean.singleseason_subset[1, survey]]
              dissimilarities_full.r[, "survey_unit" := all_survey_units[i]]
              #add year for these values
              dissimilarities_full.r[,  "year" := years[j]]
              
              #reorder
              dissimilarities_full.r <-  dissimilarities_full.r[,.(survey, survey_unit, year, dissimilarity_metric, annual_dissimilarity_value)]
   
              #remove full dataset
              rm(dissimilarities_full)
              
              #bind with full for this reg
              distances_dissimilarities_onereg <- rbind(distances_dissimilarities_onereg, dissimilarities_full.r)
            
          } #closes if it's in bio subset
              
########################################################################
########################################################################
  #Third, if data are available, calculate Bray Curtis dissimilarity metrics based on abundance
              
    if(all_survey_units[i] %in% abun_subset) { #if abundance data is available
            
            #if some rows have num_cpue missing,get rid of these rows
            reduced_year_abun <- copy(reduced_year.u[complete.cases(reduced_year.u[, num_cpue]), ])
            
              reduced_year_wide <- dcast(reduced_year_abun,  key_ID + year ~ accepted_name,  value.var = "num_cpue",  fun.aggregate = sum) #longitude to wide data for community matrix,  column names are cell then species
              
              
              ncols <- ncol(reduced_year_wide)
              communitymatrix <- reduced_year_wide[, 3:ncols] #community matrix

            
              #list of haul_id keys
              key_IDs_subset <- reduced_year_wide[,key_ID]
            
              #Calculate Bray Curtis dissimilarity values
              dissimilarities_abundance <- beta.pair.abund(communitymatrix,  index.family = "bray") #dissimilarity 
             
              #make into matrix
              dissimilarities_abundance_balanced.m <- as.matrix(dissimilarities_abundance$beta.bray.bal,  labels=TRUE) #bal = balanced
              dissimilarities_abundance_gradient.m <- as.matrix(dissimilarities_abundance$beta.bray.gra,  labels=TRUE) #gra = gradient
              dissimilarities_abundance_total.m <- as.matrix(dissimilarities_abundance$beta.bray,  labels=TRUE) #total
              
              colnames(dissimilarities_abundance_balanced.m) <- rownames(dissimilarities_abundance_balanced.m) <- key_IDs_subset
              colnames(dissimilarities_abundance_gradient.m) <- rownames(dissimilarities_abundance_gradient.m) <- key_IDs_subset
              colnames(dissimilarities_abundance_total.m) <- rownames(dissimilarities_abundance_total.m) <- key_IDs_subset
            
            
              #reshape dissimilarities
              dissimilarities_abundance_balanced.l <- reshape2::melt(dissimilarities_abundance_balanced.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "bray_curtis_dissimilarity_balanced_abundance")
              dissimilarities_abundance_gradient.l <- reshape2::melt(dissimilarities_abundance_gradient.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "bray_curtis_dissimilarity_gradient_abundance")
              dissimilarities_abundance_total.l <- reshape2::melt(dissimilarities_abundance_total.m,  varnames = c("haul_id1",  "haul_id2"),  value.name = "bray_curtis_dissimilarity_total_abundance")
              
              #and then to data table format
              dissimilarities_abundance_balanced.l <- data.table(dissimilarities_abundance_balanced.l)
              dissimilarities_abundance_gradient.l <- data.table(dissimilarities_abundance_gradient.l)
              dissimilarities_abundance_total.l <- data.table(dissimilarities_abundance_total.l)
            
            #merge into single data table
              dissimilarities_abundance_all <- dissimilarities_abundance_balanced.l[dissimilarities_abundance_gradient.l, on = c("haul_id1","haul_id2")]
              
               dissimilarities_abundance_all <- dissimilarities_abundance_all[dissimilarities_abundance_total.l, on = c("haul_id1","haul_id2")]
                            
              #again, wide to long
               dissimilarities_abundance_all.l <- reshape2::melt(dissimilarities_abundance_all,
              id.vars = c("haul_id1",  "haul_id2"), variable.name = "dissimilarity_metric", value.name = "value")
            
              #merge distance with dissimilarity for this year with both metrics of dissimilarity
              dissimilarities_full <- haul_id_distances.l[dissimilarities_abundance_all.l,  on = c("haul_id1",  "haul_id2")]
              
              
              #delete if haul_id2 < haul_id1 (deletes comparisons between same site (0 inflated) and any duplicate comparisons)
              dissimilarities_full <- dissimilarities_full[haul_id2 < haul_id1]
            
              #take averages
              #yearly means, deleted a few rogue NAs for balanced changes and abundance gradients
                dissimilarities_full[,annual_dissimilarity_value := mean(value),.(dissimilarity_metric)]

                  #unique rows
                  dissimilarities_full.r <- unique(dissimilarities_full[,.(dissimilarity_metric, annual_dissimilarity_value)])

              #add survey survey unit
              dissimilarities_full.r[, "survey" := FishGlob_clean.singleseason_subset[1, survey]]
              dissimilarities_full.r[, "survey_unit" := all_survey_units[i]]
              #add year for these values
              dissimilarities_full.r[,  "year" := years[j]]
              
              #reorder
              dissimilarities_full.r <-  dissimilarities_full.r[,.(survey, survey_unit, year, dissimilarity_metric, annual_dissimilarity_value)]
   
              #remove full dataset
              rm(dissimilarities_full)
              
              #bind with full for this reg
              distances_dissimilarities_onereg <- rbind(distances_dissimilarities_onereg, dissimilarities_full.r)    
              
          
              } #closes if it is abundance based
      
    
              print(paste0(j, "/", length(years))) #print year that we're on

  
         } #closes year
  
  #save the output from this region
  filename <- paste0(all_survey_units[i],"_dissimilarity.rds")
  saveRDS(distances_dissimilarities_onereg, here::here("output","dissimilarities","by_region",filename))
  rm(distances_dissimilarities_onereg) #attempt to save some memory here
  
  print(paste0("We have cycled through ",  i, " of ", length(all_survey_units),  " surveys"))
  
  } #closes survey/region

#merge all years into distances_dissimilarities_allyears
files <- list.files(here::here("output","dissimilarities","by_region"))

for(i in 1:length(files)){
  regional_dissimilarity <- readRDS(here::here("output","dissimilarities","by_region",files[i]))
  distances_dissimilarities_allyears <- rbind(distances_dissimilarities_allyears, regional_dissimilarity)
}


#Be sure to check which one of these you actually want to un-hash!

saveRDS(distances_dissimilarities_allyears,  here::here("output","dissimilarities", "distances_dissimilarities_allyears.rds"))

#distances_dissimilarities_allyears <- readRDS(here::here("output","dissimilarities", "distances_dissimilarities_allyears.rds"))
```
 




Note that this outputs some NA biomass dissimilarity values for SCS and NEUS. I will NOT be using biomass going forward, so it's okay.





















###SCRATCH BELOW (Probably can be deleted)





Box plot for each region
```{r box plot each region}
box_plots_jaccard <- list()
box_plots_bray <- list()

bray_model_outputs <- data.table()

bray_model_outputs <- as.data.table(matrix(nrow = length(all_survey_units)))
bray_model_outputs[,  survey:=as.character(V1)][,  season:=as.character(V1)][,  season_survey:=as.character(V1)][,  bray_coef:=as.numeric(V1)][,  bray_intercept := as.numeric(V1)][, bray_coef_pvalue := as.numeric(V1)][, bray_r_squared := as.numeric(V1)]
bray_model_outputs[,  V1 := NULL]

jaccard_model_outputs <- as.data.table(matrix(nrow = length(all_survey_units)))

jaccard_model_outputs <- as.data.table(matrix(nrow = length(all_survey_units)))
jaccard_model_outputs[,  survey:=as.character(V1)][,  season:=as.character(V1)][,  season_survey:=as.character(V1)][,  jaccard_coef:=as.numeric(V1)][,  jaccard_intercept := as.numeric(V1)][, jaccard_coef_pvalue := as.numeric(V1)][, jaccard_r_squared := as.numeric(V1)]
jaccard_model_outputs[,  V1 := NULL]


distances_dissimilarities_allyears[, year_f := as.factor(year)]

#in case you didn't make it earlier
all_survey_units <- unique(distances_dissimilarities_allyears[, survey_unit])

for (i in 1:length(all_survey_units)) {
      distances_dissimilarities_allyears_subset <- distances_dissimilarities_allyears[season_survey == all_survey_units[i]]
      
    #jaccard similarity
#    box_plots_jaccard[[i]] <- ggplot(distances_dissimilarities_allyears_subset, aes(year_f,  #jaccard_dissimilarity_turnover)) +
#      geom_boxplot(outlier.shape = NA,  lwd = 0.2) +
#      labs(x="Year",  y = "Jaccard Dissimilarity") +
#      geom_smooth(method = "lm",  se=FALSE,  color="red",  aes(group=1),  lwd = 0.3) +
#      stat_regline_equation() +
#      theme_classic() +
#      theme(axis.text.x = element_text(angle = 90))
#    
#    #bray curtis similarity
#    box_plots_bray[[i]] <- ggplot(distances_dissimilarities_allyears_subset, aes(year_f, bray_curtis_dissimilari#ty_balanced)) +
#      geom_boxplot(outlier.shape = NA,  lwd = 0.2) +
#      labs(x="Year",  y = "Bray Curtis Dissimilarity") +
#      geom_smooth(method = "lm",  se=FALSE,  color="red",  aes(group=1),  lwd = 0.3) +
#      stat_regline_equation() +
#      theme_classic() +
#      theme(axis.text.x = element_text(angle = 90))
    #START HERE GET THESE TO ACTUALLY SAVE
    #corresponding models
    avg_jaccard_mod <- lm(data = distances_dissimilarities_allyears_subset,  formula = jaccard_dissimilarity_turnover ~ as.numeric(year))
    
    jaccard_model_outputs[i,  "survey"] <- distances_dissimilarities_allyears_subset[1,  survey]
    jaccard_model_outputs[i,  "season"] <- distances_dissimilarities_allyears_subset[1,  season]
    jaccard_model_outputs[i,  "season_survey"] <- distances_dissimilarities_allyears_subset[1,  season_survey]
    
    #coef
    
    jaccard_model_outputs[i, "jaccard_coef"] <- avg_jaccard_mod$coefficients[[2]]
    
    #intercept
    jaccard_model_outputs[i, "jaccard_intercept"] <- avg_jaccard_mod$coefficients[[1]]
    
    #p-value
     jaccard_model_outputs[i, "jaccard_coef_pvalue"] <- summary(avg_jaccard_mod)$coefficients[2, 4]  
    
    #R^2
    jaccard_model_outputs[i, "jaccard_r_squared"] <- summary(avg_jaccard_mod)$r.squared
    
    #bray
    
    avg_bray_mod <- lm(data = distances_dissimilarities_allyears_subset,  formula = bray_curtis_dissimilarity_balanced ~ as.numeric(year))
    
    bray_model_outputs[i,  "survey"] <- distances_dissimilarities_allyears_subset[1,  survey]
    bray_model_outputs[i,  "season"] <- distances_dissimilarities_allyears_subset[1,  season]
    bray_model_outputs[i,  "season_survey"] <- distances_dissimilarities_allyears_subset[1,  season_survey]
    
    #coef
    
    bray_model_outputs[i, "bray_coef"] <- avg_bray_mod$coefficients[[2]]
    #intercept
    bray_model_outputs[i, "bray_intercept"] <- avg_bray_mod$coefficients[[1]]
    
    #p-value
    bray_model_outputs[i, "bray_coef_pvalue"] <- summary(avg_bray_mod)$coefficients[2, 4]  
    
    #R^2
    bray_model_outputs[i, "bray_r_squared"] <- summary(avg_bray_mod)$r.squared
    


}



#save plots and models as objects
saveRDS(jaccard_model_outputs,  here::here("output", "distance_decay", "jaccard_model_outputs.rds"))
saveRDS(bray_model_outputs,  here::here("output", "distance_decay", "bray_model_outputs.rds"))

saveRDS(box_plots_jaccard,  here::here("output", "distance_decay", "box_plots_jaccard.rds"))
saveRDS(box_plots_bray,  here::here("output", "distance_decay", "box_plots_bray.rds"))

#save plots as images

for (i in 1:length(all_survey_units)) {
  filename_jaccard <- paste0(all_survey_units[i],  "_jaccard_box_plot.jpg")
  ggsave(box_plots_jaccard[[i]],  path = here::here("figures",  "distance_decay"),  filename = filename_jaccard)
  
  filename_bray <- paste0(all_survey_units[i],  "_bray_box_plot.jpg")
  ggsave(box_plots_bray[[i]],  path = here::here("figures",  "distance_decay"),  filename = filename_bray)
}
```

Overall slope

Dornelas 2014: "To estimate the global long-term trends in diversity,  to each of the 14 metrics (10 community structure and 4 composition turnover metrics),  

- we first fit a linear model with a single slope but a different intercept and a residual variance for each time series,  by using generalized least squares (GLS). Additionally,  

- we fit a linear model to each time series allowing a different slope and an intercept,  by using ordinary least squares (OLS). 

The R squared value and the p-value of each slope coefficient (the OLS estimate) are also calculated. However,  the provided p-value may be overly confident due to the unknown correlated structure so a careful interpretation is required. These statistics are included to provide intuitive information of the fitted linear trend of each time series,  rather than in a classical hypothesis-testing context."

GLS: John Fox & Sanford Weisberg 2019
https://socialsciences.mcmaster.ca/jfox/Books/Companion/appendices/Appendix-Timeseries-Regression.pdf
- The gls() function in the nlme package (Pinheiro et al.,  2018), 

Linear model with single slope but different interceept and residual variance for each time series

First,  just linear model 
```{r}
overall_mod <- gls(bray_curtis_dissimilarity_balanced ~ year + season_survey,  data = distances_dissimilarities_allyears)
```



Averages for each survey_unit
```{r}
colnames(distances_dissimilarities_allyears)


distances_dissimilarities_allyears[, mean_jaccard := mean(jaccard_dissimilarity_turnover),  .(survey,  season,  year)]
distances_dissimilarities_allyears[, mean_bray := mean(bray_curtis_dissimilarity_balanced),  .(survey,  season,  year)]
```