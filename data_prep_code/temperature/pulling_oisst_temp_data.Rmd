---
title: "Pulling OISST Temp Data"
output: html_notebook
---

This code is Script 5 for Kitchel et al. TITLE manuscript.

- This project is a collaborative effort to describe changes in taxonomic composition  of fish communities around the world--as sampled by bottom trawl surveys.

- Code by Zoë J. Kitchel

SESSION INFO TO DO


Daily SST Temperature

```{r setup}
library(dplyr) # A staple for modern data management in R
library(lubridate) # Useful functions for dealing with dates
library(ggplot2) # The preferred library for data visualisation
library(tidync) # For easily dealing with NetCDF data
library(rerddap) # For easily downloading subsets of data
library(stringr)
library(data.table)

#pull in data for year and lat lon restrictions
FishGlob_clean <- readRDS(here::here("data", "cleaned", "FishGlob.wellsampledyearscells_complete.final.rds"))
```

Unique Lat Lon Year for each Survey/season
```{r unique lat lon}
unique_lat_lon_year <- unique(FishGlob_clean[,.(latitude, longitude, year, survey, survey_unit)])

#data range for this data is (-179.875, 179.875), so I will trim to this
unique_lat_lon_year[,longitude_trim := ifelse(longitude < -179.875, -179.875, ifelse(longitude > 179.875, 179.875, longitude))]

summary(unique_lat_lon_year[,longitude_trim])
```

Visualize what data look like
```{r viz data}
# The information for the NOAA OISST data
rerddap::info(datasetid = "ncdcOisst21Agg_LonPM180", url = "https://coastwatch.pfeg.noaa.gov/erddap/")

# Note that there is also a version with lon values from 0 yo 360
rerddap::info(datasetid = "ncdcOisst21Agg", url = "https://coastwatch.pfeg.noaa.gov/erddap/")
```

Write function to prep data based on start and end dates and provided lat long
```{r function to prep data}
# This function downloads and prepares data based on user provided start and end dates
OISST_sub_dl <- function(time_df, this_survey_unit){
  OISST_dat <- griddap(x = "ncdcOisst21Agg_LonPM180", 
                       url = "https://coastwatch.pfeg.noaa.gov/erddap/", 
                       time = c(time_df$start, time_df$end), 
                       zlev = c(0, 0),
                       latitude = c(min(unique_lat_lon_year[survey_unit == this_survey_unit]$latitude),
                                    max(unique_lat_lon_year[survey_unit == this_survey_unit]$latitude)),
                       longitude = c(min(unique_lat_lon_year[survey_unit == this_survey_unit]$longitude_trim),
                                    max(unique_lat_lon_year[survey_unit == this_survey_unit]$longitude_trim)),
                       fields = "sst")$data %>% 
    mutate(time = as.Date(stringr::str_remove(time, "T00:00:00Z"))) %>% 
    dplyr::rename(t = time, temp = sst) %>% 
    select(lon, lat, t, temp) %>% 
    na.omit()
}
```

Setup dates we will pull data for. For ease, I'm going to pull entire time period
```{r setup dates in dl_year}
    
dl_years <- data.frame(date_index = 1:5,
                           start = as.Date(c("1981-09-01", "1989-01-01", 
                                             "1997-01-01", "2005-01-01", "2013-01-01")),
                           end = as.Date(c("1988-12-31", "1996-12-31", 
                                           "2004-12-31", "2012-12-31", "2021-12-31")))



```

I am running AI separately because it spans dateline, and I need to do some edits

```{r AI alone}
# Download all of the data with one nested request
# The time this takes will vary greatly based on connection speed

    system.time(
      OISST_data <- dl_years %>% 
        group_by(date_index) %>% 
        group_modify(~OISST_sub_dl(.x, "AI")) %>% 
        ungroup() %>% 
        select(lon, lat, t, temp)
    ) # 38 seconds, ~8 seconds per batch


OISST_data_AI <- as.data.table(OISST_data)

AI_min_positive <- min(unique_lat_lon_year[longitude > 150 & survey == "AI"]$longitude)
AI_max_negative <-max(unique_lat_lon_year[longitude < 0 & survey == "AI"]$longitude)

OISST_data_AI <- OISST_data_AI[lon >= AI_min_positive | lon <= AI_max_negative,][,lon_s := ifelse(lon > 160, lon-360, lon)]

#edit, because we don't actually need all of this data
hist(FishGlob_clean[survey == "AI", longitude])
#for just AI 
#2024.317  159.159 4585.945 

#save AI data
saveRDS(OISST_data_AI, here::here("data","Temperature","OISST_data_AI.rds"))
```


Plot temp for one period in AI just to make sure it looks right

```{r test plot AI}
OISST_data_AI %>% 
  filter(t == "2018-12-01") %>% 
  ggplot(aes(x = lon_s, y = lat)) +
  geom_tile(aes(fill = temp)) +
  borders() + # Activate this line to see the global map
  scale_fill_viridis_c() +
  coord_quickmap(expand = F) +
  labs(x = NULL, y = NULL, fill = "SST (°C)") +
  theme(legend.position = "bottom")
```

Loop to pull data for all regions (works best on remote server, takes quite a bit of time)
```{r loop to pull in all regions past AI}
for (i in 2:length(all_survey_units)) { #skip AI, pull separately because it spans dateline
    system.time(
      OISST_data <- dl_years %>% 
        group_by(date_index) %>% 
        group_modify(~OISST_sub_dl(.x, all_survey_units[i])) %>% 
        ungroup() %>% 
        select(lon, lat, t, temp)
    ) # 38 seconds, ~8 seconds per batch

    assign(paste0("OISST_data_",all_survey_units[i]), OISST_data) #check this
    
    saveRDS(get(paste0("OISST_data_",all_survey_units[i])), here::here("data","Temperature",paste0("OISST_data_",all_survey_units[i],".rds")))
    
}
```

Average Values

First go from daily temp to average monthly temp. We need mean temp 12 months before May, max temp 12 months before May, and min temp 12 months before June. At some time in the future, I may want to extract values at exact temp values, but not sure it matters much now. Instead, I'll take yearly:
* mean
* max
* min
* SD
* difference (avg difference, mean(dist(v, method = "manhattan")) )

And now all other regions
```{r loop for average values}

OISST_data_temp_avgs_full <- data.table()

for (i in 1:length(all_survey_units)) {
  min_month <- min(FishGlob_clean[survey_unit == all_survey_units[i]]$month)
  
  #pull in data from rds files if not already in console
  
  assign(paste0("OISST_data_",all_survey_units[i]), readRDS(here::here("data","Temperature",paste0("OISST_data_",all_survey_units[i],".rds"))))
  
  OISST_data <- data.table(get(paste0("OISST_data_",all_survey_units[i])))
  
  OISST_data[,month := month(t)][,year := year(t)]
  
  #for each region, how does temp compare to avg temp for that region
  OISST_data[,temp_scaled := scale(temp)]

  OISST_data[, year_for_avg := ifelse(month >= min_month, year+1, year)][, yearly_mean_bypoint := mean(temp), .(year_for_avg, lat, lon)][, yearly_max_bypoint := max(temp), .(year_for_avg, lat, lon)][, yearly_min_bypoint := min(temp), .(year_for_avg, lat, lon)][, montly_mean_bypoint := mean(temp),.(year_for_avg,lat,lon,month)][, yearly_mean_bypoint_scaled := mean(temp_scaled), .(year_for_avg, lat, lon)][, montly_mean_bypoint_scaled := mean(temp_scaled),.(year_for_avg,lat,lon,month)]
  
  #for min, max, and mean, first temp is avg by month at each lat/lon, THEN we take mean, max, and min monthly temp per year (balances out any weird values)
  #for SD, we calculate a yearly mean by lat/lon, and then look at standard deviation
  OISST_data[, sst_min := min(montly_mean_bypoint), year_for_avg][, sst_max := max(montly_mean_bypoint), year_for_avg][, sst_mean := mean(montly_mean_bypoint), year_for_avg][, sst_SD_mean := sd(yearly_mean_bypoint), year_for_avg][, sst_SD_max := sd(yearly_max_bypoint), year_for_avg][, sst_SD_min := sd(yearly_min_bypoint), year_for_avg] #this doesn't take into consideration spatial component for sst min max or mean, I want to calculate mean at each point, and THEN take SD I think
   
  #scaled versions
     #for min, max, and mean, first temp is avg by month at each lat/lon, THEN we take mean, max, and min monthly temp per year (balances out any weird values)
  #for SD, we calculate a yearly mean by lat/lon, calculate standard deviation, and then scale standard deviation
  OISST_data[, sst_min_scaled := min(montly_mean_bypoint_scaled), year_for_avg][, sst_max_scaled := max(montly_mean_bypoint_scaled), year_for_avg][, sst_mean_scaled := mean(montly_mean_bypoint_scaled), year_for_avg][, sst_SD_scaled := sd(yearly_mean_bypoint_scaled), year_for_avg]
  
  #for difference to calculate with limited memory, I will need to first simplify datatable
  OISST_data_simplified <- unique(OISST_data[,.(yearly_mean_bypoint, yearly_mean_bypoint_scaled, year_for_avg)])
                                  
OISST_data_simplified[, sst_difference_mean := mean(dist(yearly_mean_bypoint, method = "manhattan")), year_for_avg][, sst_difference_mean_scaled := mean(dist(yearly_mean_bypoint_scaled, method = "manhattan")), year_for_avg]
  
#unique values
  OISST_data_temp_avgs <- unique(OISST_data[,.(year_for_avg, sst_min, sst_max, sst_mean, sst_SD, sst_min_scaled, sst_max_scaled, sst_mean_scaled, sst_SD_scaled)])
  
  OISST_data_simplified_avgs <- unique(OISST_data_simplified[,.(year_for_avg, sst_difference_mean, sst_difference_mean_scaled)])
  
  #link with raw temperature differences created with dist()
  OISST_data_temp_avgs <- OISST_data_temp_avgs[OISST_data_simplified_avgs, on = c("year_for_avg")]
  
  OISST_data_temp_avgs[, survey_unit := all_survey_units[i]]
  OISST_data_temp_avgs[, season := word(all_survey_units[i],2, sep = "_")]
  OISST_data_temp_avgs[, survey := word(all_survey_units[i],1, sep = "_")]
  
  OISST_data_temp_avgs_full <- rbind(OISST_data_temp_avgs_full, OISST_data_temp_avgs)
  
#  plot(OISST_data_temp_avgs$year, OISST_data_temp_avgs$sst_mean)
#  abline()
#  plot(OISST_data_temp_avgs$year, OISST_data_temp_avgs$sst_max)
#  plot(OISST_data_temp_avgs$year, OISST_data_temp_avgs$sst_min)
#  plot(OISST_data_temp_avgs$year, OISST_data_temp_avgs$sst_SD)

}


#save summary table!!!
saveRDS(OISST_data_temp_avgs_full, here::here("data","Temperature","OISST_data_temp_avgs_full.rds"))

```


